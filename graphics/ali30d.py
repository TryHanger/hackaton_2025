import sqlite3
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from sklearn.preprocessing import KBinsDiscretizer
from sklearn.neighbors import KernelDensity
from pathlib import Path
import warnings

warnings.filterwarnings('ignore')


def compare_with_join():
    """
    –ë–æ–ª–µ–µ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º JOIN –º–µ–∂–¥—É –ë–î.
    """
    try:
        # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –ë–î –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        result_conn = sqlite3.connect(':memory:')
        result_cursor = result_conn.cursor()

        # –ü—Ä–∏—Å–æ–µ–¥–∏–Ω—è–µ–º –æ–±–µ –ë–î
        result_cursor.execute("ATTACH DATABASE '../info_perevody.db' AS info_db")
        result_cursor.execute("ATTACH DATABASE '../perevody.db' AS perevody_db")

        # –°–æ–∑–¥–∞–µ–º —Ç–∞–±–ª–∏—Ü—É —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
        result_cursor.execute("""
            CREATE TABLE avg_login_interval_30d AS
            SELECT 
                i.cst_dim_id,
                i.transdate,
                i.avg_login_interval_30d,
                p.target
            FROM info_db.unique_transactions i
            LEFT JOIN perevody_db.unique_transactions p
                ON i.cst_dim_id = p.cst_dim_id 
                AND i.transdate = p.transdate
            WHERE i.avg_login_interval_30d IS NOT NULL
        """)

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        result_cursor.execute("SELECT COUNT(*) FROM avg_login_interval_30d")
        total_count = result_cursor.fetchone()[0]

        result_cursor.execute("SELECT COUNT(*) FROM avg_login_interval_30d WHERE target IS NOT NULL")
        matched_count = result_cursor.fetchone()[0]

        result_cursor.execute("SELECT COUNT(*) FROM avg_login_interval_30d WHERE target = 1")
        target_1_count = result_cursor.fetchone()[0]

        result_cursor.execute("SELECT COUNT(*) FROM avg_login_interval_30d WHERE target = 0")
        target_0_count = result_cursor.fetchone()[0]

        print("üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –°–†–ê–í–ù–ï–ù–ò–Ø:")
        print(f"–í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π: {total_count}")
        print(f"–ù–∞–π–¥–µ–Ω–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π: {matched_count}")
        print(f"–ù–µ –Ω–∞–π–¥–µ–Ω–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π: {total_count - matched_count}")
        print(f"Target = 1: {target_1_count}")
        print(f"Target = 0: {target_0_count}")

        # –í—ã–±–æ—Ä–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        result_cursor.execute("SELECT * FROM avg_login_interval_30d LIMIT 10")
        sample_results = result_cursor.fetchall()

        print("\nüîç –ü–ï–†–í–´–ï 10 –†–ï–ó–£–õ–¨–¢–ê–¢–û–í:")
        print("ID | –î–∞—Ç–∞ | avg_login_interval_30d | Target")
        print("-" * 50)
        for row in sample_results:
            print(f"{row[0]} | {row[1]} | {row[2]} | {row[3]}")

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ —Ñ–∞–π–ª –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        result_cursor.execute("""
            ATTACH DATABASE '../comparison_results.db' AS results_db
        """)
        result_cursor.execute("""
            CREATE TABLE results_db.avg_login_interval_30d AS
            SELECT * FROM avg_login_interval_30d
        """)

        print("\nüíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ comparison_results.db")

        # –û—Ç—Å–æ–µ–¥–∏–Ω—è–µ–º –ë–î
        result_cursor.execute("DETACH DATABASE info_db")
        result_cursor.execute("DETACH DATABASE perevody_db")
        result_cursor.execute("DETACH DATABASE results_db")

        return total_count

    except sqlite3.Error as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö: {e}")
        return 0


def load_data():
    import sqlite3
    import pandas as pd
    from pathlib import Path

    script_dir = Path(__file__).parent
    db_path = script_dir.parent / 'comparison_results.db'
    conn = sqlite3.connect(db_path)
    df = pd.read_sql_query(
        "SELECT avg_login_interval_30d, target FROM avg_login_interval_30d WHERE target IS NOT NULL AND avg_login_interval_30d IS NOT NULL",
        conn
    )
    conn.close()

    # --- –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ö–û–ù–í–ï–†–¢–ê–¶–ò–Ø –°–ï–ö–£–ù–î –í –î–ù–ò ---

    # 86400 —Å–µ–∫—É–Ω–¥ –≤ —Å—É—Ç–∫–∞—Ö (24 * 60 * 60).
    SECONDS_IN_DAY = 86400

    # –°–Ω–∞—á–∞–ª–∞ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è (-1)
    df['has_no_data'] = (df['avg_login_interval_30d'] == -1).astype(int)

    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∏–Ω—Ç–µ—Ä–≤–∞–ª –∏–∑ —Å–µ–∫—É–Ω–¥ –≤ –¥–Ω–∏, –∏—Å–ø–æ–ª—å–∑—É—è –º–∞—Å–∫—É, —á—Ç–æ–±—ã –Ω–µ —Ç—Ä–æ–≥–∞—Ç—å -1
    df.loc[df['avg_login_interval_30d'] != -1, 'avg_login_interval_30d'] = \
        df.loc[df['avg_login_interval_30d'] != -1, 'avg_login_interval_30d'] / SECONDS_IN_DAY

    # --- –î–ê–õ–¨–ù–ï–ô–®–ê–Ø –ü–†–ï–î–û–ë–†–ê–ë–û–¢–ö–ê (–ò–ó–ú–ï–ù–ï–ù–ê –ü–û–î –î–ù–ò) ---

    print("üîß –ü–†–ï–î–û–ë–†–ê–ë–û–¢–ö–ê –î–ê–ù–ù–´–• avg_login_interval_30d (–ü–ï–†–ï–í–ï–î–ï–ù–û –í –î–ù–ò):")
    print(
        f"–ò—Å—Ö–æ–¥–Ω—ã–π –¥–∏–∞–ø–∞–∑–æ–Ω (–î–ù–ò): {df['avg_login_interval_30d'].min():.1f} - {df['avg_login_interval_30d'].max():.1f}")

    # –û–±—Ä–µ–∑–∞–µ–º —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ (–º–∞–∫—Å 30 –¥–Ω–µ–π)
    # –¢–µ–ø–µ—Ä—å max_login = 2712540.0 —Å–µ–∫—É–Ω–¥ (31.4 –¥–Ω—è) –æ–±—Ä–µ–∂–µ—Ç—Å—è –¥–æ 30.0 –¥–Ω–µ–π.
    df['interval_processed'] = df['avg_login_interval_30d'].clip(upper=30)

    # –°–æ–∑–¥–∞–µ–º –∏–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø—Ä–∏–∑–Ω–∞–∫ (—á–µ–º –º–µ–Ω—å—à–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª = –≤—ã—à–µ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å)
    df['activity_level'] = 30 - df['interval_processed']
    df['activity_level'] = df['activity_level'].clip(lower=0)

    print(
        f"–ü–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ (–æ–±—Ä–µ–∑–∫–∞ –¥–æ 30 –¥–Ω–µ–π): {df['interval_processed'].min():.1f} - {df['interval_processed'].max():.1f}")
    print(f"–û—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π: {df['has_no_data'].sum()}")

    return df


def automatic_binning_analysis(df):
    """–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –±–∏–Ω–Ω–∏–Ω–≥ —Å —Ä–∞–∑–Ω—ã–º–∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏—è–º–∏."""

    print("\n" + "=" * 60)
    print("1. –ê–í–¢–û–ú–ê–¢–ò–ß–ï–°–ö–ò–ô –ë–ò–ù–ù–ò–ù–ì")
    print("=" * 60)

    # –ò–°–ü–û–õ–¨–ó–£–ï–ú –û–ë–†–ê–ë–û–¢–ê–ù–ù–´–ï –î–ê–ù–ù–´–ï
    X = df['interval_processed'].values.reshape(-1, 1)

    # –†–∞–∑–Ω—ã–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –±–∏–Ω–Ω–∏–Ω–≥–∞
    strategies = {
        'uniform': '–†–∞–≤–Ω–æ–º–µ—Ä–Ω—ã–π',
        'quantile': '–ö–≤–∞–Ω—Ç–∏–ª—å–Ω—ã–π',
        'kmeans': 'K-—Å—Ä–µ–¥–Ω–∏—Ö'
    }

    fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    axes = axes.ravel()

    for idx, (strategy, name) in enumerate(strategies.items()):
        # –°–æ–∑–¥–∞–µ–º –±–∏–Ω—ã
        discretizer = KBinsDiscretizer(n_bins=8, encode='ordinal', strategy=strategy)
        bins_array = discretizer.fit_transform(X).flatten()

        # –ê–Ω–∞–ª–∏–∑ fraud rate –ø–æ –±–∏–Ω–∞–º
        df_binned = df.copy()
        df_binned['bin'] = bins_array
        bin_stats = df_binned.groupby('bin').agg({
            'interval_processed': ['min', 'max', 'count'],
            'target': ['sum', 'mean']
        }).round(3)

        bin_stats.columns = ['min_interval', 'max_interval', 'total_count', 'fraud_count', 'fraud_rate']
        bin_stats['fraud_rate_pct'] = (bin_stats['fraud_rate'] * 100).round(2)

        # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
        ax = axes[idx]
        bins_centers = (bin_stats['min_interval'] + bin_stats['max_interval']) / 2
        ax.plot(bins_centers, bin_stats['fraud_rate_pct'], 'o-', linewidth=2, markersize=8)
        ax.set_title(f'{name} –±–∏–Ω–Ω–∏–Ω–≥\n({strategy})', fontsize=14)
        ax.set_xlabel('–°—Ä–µ–¥–Ω–∏–π –∏–Ω—Ç–µ—Ä–≤–∞–ª –º–µ–∂–¥—É –ª–æ–≥–∏–Ω–∞–º–∏ (–¥–Ω–∏)', fontsize=12)  # –ò–°–ü–†–ê–í–õ–ï–ù–ê –ü–û–î–ü–ò–°–¨
        ax.set_ylabel('Fraud Rate (%)', fontsize=12)
        ax.grid(True, alpha=0.3)

        # –î–æ–±–∞–≤–ª—è–µ–º –∑–Ω–∞—á–µ–Ω–∏—è
        for i, (center, rate) in enumerate(zip(bins_centers, bin_stats['fraud_rate_pct'])):
            ax.annotate(f'{rate}%', (center, rate), xytext=(0, 10),
                        textcoords='offset points', ha='center', fontsize=9)

        print(f"\n{name} –±–∏–Ω–Ω–∏–Ω–≥:")
        print(bin_stats[['min_interval', 'max_interval', 'total_count', 'fraud_rate_pct']])

    # –†—É—á–Ω–æ–π –±–∏–Ω–Ω–∏–Ω–≥ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞
    axes[3].axis('off')
    plt.tight_layout()
    plt.show()

    return df


def trend_analysis(df):
    """–°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ —Ç—Ä–µ–Ω–¥–∞ —Ä–∏—Å–∫–∞ –¥–ª—è avg_login_interval_30d."""

    print("\n" + "=" * 60)
    print("2. –°–¢–ê–¢–ò–°–¢–ò–ß–ï–°–ö–ò–ô –ê–ù–ê–õ–ò–ó –¢–†–ï–ù–î–ê")
    print("=" * 60)

    # –û–ü–¢–ò–ú–ê–õ–¨–ù–´–ï –ë–ò–ù–´ –î–õ–Ø –ò–ù–¢–ï–†–í–ê–õ–ê –ú–ï–ñ–î–£ –õ–û–ì–ò–ù–ê–ú–ò
    bins = [-2, -0.5, 1, 3, 7, 14, 30, 31]  # –≤–∫–ª—é—á–∞–µ–º -1 –∏ –æ–±—Ä–µ–∑–∞–µ–º –Ω–∞ 30
    labels = ['–ù–µ—Ç_–¥–∞–Ω–Ω—ã—Ö', '–û—á–µ–Ω—å_—á–∞—Å—Ç–æ', '–ï–∂–µ–¥–Ω–µ–≤–Ω–æ', '–†–∞–∑_–≤_3–¥–Ω—è', '–†–∞–∑_–≤_–Ω–µ–¥–µ–ª—é', '–†–∞–∑_–≤_2–Ω–µ–¥–µ–ª–∏', '–†–µ–¥–∫–æ']

    df['bin'] = pd.cut(df['avg_login_interval_30d'], bins=bins, labels=labels, right=False)
    trend_data = df.groupby('bin').agg({
        'target': ['count', 'sum', 'mean'],
        'avg_login_interval_30d': 'median'
    }).round(4)

    trend_data.columns = ['total', 'fraud_count', 'fraud_rate', 'median_interval']
    trend_data['fraud_rate_pct'] = (trend_data['fraud_rate'] * 100).round(2)

    # –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ —Ç–µ—Å—Ç—ã
    X = np.arange(len(trend_data))
    Y = trend_data['fraud_rate'].values

    # –õ–∏–Ω–µ–π–Ω–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è –¥–ª—è —Ç—Ä–µ–Ω–¥–∞
    slope, intercept, r_value, p_value, std_err = stats.linregress(X, Y)

    # –¢–µ—Å—Ç –ú–∞–Ω–Ω–∞-–ö–µ–Ω–¥–∞–ª–ª–∞ (–º–æ–Ω–æ—Ç–æ–Ω–Ω–æ—Å—Ç—å)
    from scipy.stats import kendalltau
    tau, p_tau = kendalltau(X, Y)

    print("üìà –°–¢–ê–¢–ò–°–¢–ò–ö–ê –¢–†–ï–ù–î–ê:")
    print(f"–õ–∏–Ω–µ–π–Ω—ã–π —Ç—Ä–µ–Ω–¥: slope = {slope:.6f}, R¬≤ = {r_value ** 2:.4f}")
    print(f"P-value –ª–∏–Ω–µ–π–Ω–æ—Å—Ç–∏: {p_value:.6f}")
    print(f"–¢–µ—Å—Ç –ö–µ–Ω–¥–∞–ª–ª–∞: tau = {tau:.4f}, p-value = {p_tau:.6f}")
    print(f"–ú–æ–Ω–æ—Ç–æ–Ω–Ω–æ—Å—Ç—å: {'–î–ê' if p_tau < 0.05 and tau > 0 else '–ù–ï–¢'}")

    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ç—Ä–µ–Ω–¥–∞
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))

    # –ì—Ä–∞—Ñ–∏–∫ —Ç—Ä–µ–Ω–¥–∞
    ax1.plot(X, Y * 100, 'o-', linewidth=3, markersize=8, label='–ù–∞–±–ª—é–¥–∞–µ–º—ã–π fraud rate')

    # –õ–∏–Ω–µ–π–Ω—ã–π —Ç—Ä–µ–Ω–¥
    trend_line = intercept + slope * X
    ax1.plot(X, trend_line * 100, '--', color='red', linewidth=2,
             label=f'–õ–∏–Ω–µ–π–Ω—ã–π —Ç—Ä–µ–Ω–¥ (R¬≤={r_value ** 2:.3f})')

    ax1.set_title('Fraud Rate vs –ò–Ω—Ç–µ—Ä–≤–∞–ª –º–µ–∂–¥—É –ª–æ–≥–∏–Ω–∞–º–∏', fontsize=16, fontweight='bold')
    ax1.set_xlabel('–£—Ä–æ–≤–µ–Ω—å –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏', fontsize=12)
    ax1.set_ylabel('Fraud Rate (%)', fontsize=12)
    ax1.set_xticks(X)
    ax1.set_xticklabels(labels, rotation=45)
    ax1.legend()
    ax1.grid(True, alpha=0.3)

    # –î–æ–±–∞–≤–ª—è–µ–º –∑–Ω–∞—á–µ–Ω–∏—è
    for i, (x, y) in enumerate(zip(X, Y * 100)):
        ax1.annotate(f'{y:.1f}%', (x, y), xytext=(0, 10),
                     textcoords='offset points', ha='center', fontweight='bold')

    # –î–µ—Ç–∞–ª—å–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞
    ax2.axis('off')
    table_data = []
    for bin_name in labels:
        if bin_name in trend_data.index:
            row = trend_data.loc[bin_name]
            table_data.append([
                bin_name, row['total'], row['fraud_count'],
                f"{row['fraud_rate_pct']}%", f"{row['median_interval']:.1f}"
            ])

    table = ax2.table(cellText=table_data,
                      colLabels=['–ê–∫—Ç–∏–≤–Ω–æ—Å—Ç—å', '–í—Å–µ–≥–æ', 'Fraud', 'Fraud%', '–ú–µ–¥–∏–∞–Ω–∞_–∏–Ω—Ç–µ—Ä–≤–∞–ª–∞'],
                      loc='center',
                      cellLoc='center')
    table.auto_set_font_size(False)
    table.set_fontsize(10)
    table.scale(1, 1.5)
    ax2.set_title('–î–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —É—Ä–æ–≤–Ω—è–º –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏', fontsize=14, fontweight='bold')

    plt.tight_layout()
    plt.show()

    return trend_data


def tail_analysis(df):
    """–ê–Ω–∞–ª–∏–∑ —Ä–µ–¥–∫–∏—Ö –∑–Ω–∞—á–µ–Ω–∏–π (—Ö–≤–æ—Å—Ç–æ–≤ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è)."""

    print("\n" + "=" * 60)
    print("3. –ê–ù–ê–õ–ò–ó –•–í–û–°–¢–û–í –†–ê–°–ü–†–ï–î–ï–õ–ï–ù–ò–Ø")
    print("=" * 60)

    # –ò–°–ü–û–õ–¨–ó–£–ï–ú –û–ë–†–ê–ë–û–¢–ê–ù–ù–´–ï –î–ê–ù–ù–´–ï
    mean_interval = df['interval_processed'].mean()
    std_interval = df['interval_processed'].std()
    outlier_threshold = mean_interval + 3 * std_interval

    outliers = df[df['interval_processed'] > outlier_threshold]
    normal_data = df[df['interval_processed'] <= outlier_threshold]

    print(f"–ü–æ—Ä–æ–≥ –≤—ã–±—Ä–æ—Å–æ–≤: > {outlier_threshold:.1f} –¥–Ω–µ–π")
    print(f"–í—ã–±—Ä–æ—Å–æ–≤: {len(outliers)} –∑–∞–ø–∏—Å–µ–π ({len(outliers) / len(df) * 100:.2f}%)")
    print(f"–í—ã–±—Ä–æ—Å—ã - Fraud Rate: {outliers['target'].mean() * 100:.2f}%")
    print(f"–ù–æ—Ä–º–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è - Fraud Rate: {normal_data['target'].mean() * 100:.2f}%")

    # –ê–Ω–∞–ª–∏–∑ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –±–µ–∑ –¥–∞–Ω–Ω—ã—Ö
    no_data = df[df['has_no_data'] == 1]
    if len(no_data) > 0:
        print(f"\nüìä –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–ò –ë–ï–ó –î–ê–ù–ù–´–•:")
        print(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ: {len(no_data)} –∑–∞–ø–∏—Å–µ–π")
        print(f"Fraud Rate: {no_data['target'].mean() * 100:.2f}%")

    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ö–≤–æ—Å—Ç–æ–≤
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))

    # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å –≤—ã–¥–µ–ª–µ–Ω–∏–µ–º –≤—ã–±—Ä–æ—Å–æ–≤
    ax1.hist(normal_data['interval_processed'], bins=30, alpha=0.7,
             color='blue', label=f'–ù–æ—Ä–º–∞–ª—å–Ω—ã–µ (‚â§{outlier_threshold:.0f}–¥–Ω)')
    ax1.hist(outliers['interval_processed'], bins=10, alpha=0.7,
             color='red', label=f'–í—ã–±—Ä–æ—Å—ã (> {outlier_threshold:.0f}–¥–Ω)')
    ax1.axvline(outlier_threshold, color='black', linestyle='--', linewidth=2, label='–ü–æ—Ä–æ–≥ –≤—ã–±—Ä–æ—Å–æ–≤')
    ax1.set_title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–≤ –º–µ–∂–¥—É –ª–æ–≥–∏–Ω–∞–º–∏', fontsize=14)
    ax1.set_xlabel('–ò–Ω—Ç–µ—Ä–≤–∞–ª –º–µ–∂–¥—É –ª–æ–≥–∏–Ω–∞–º–∏ (–¥–Ω–∏)', fontsize=12)
    ax1.set_ylabel('–ß–∞—Å—Ç–æ—Ç–∞', fontsize=12)
    ax1.legend()
    ax1.grid(True, alpha=0.3)

    # Fraud rate –ø–æ –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª—è–º –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
    percentiles = np.arange(0, 101, 5)
    percentile_values = np.percentile(df['activity_level'], percentiles)  # –∏—Å–ø–æ–ª—å–∑—É–µ–º –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å!
    percentile_fraud = []

    for p in percentiles:
        threshold = np.percentile(df['activity_level'], p)
        high_activity = df[df['activity_level'] >= threshold]  # –≤—ã—Å–æ–∫–∏–π —É—Ä–æ–≤–µ–Ω—å –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
        if len(high_activity) > 0:
            fraud_rate = high_activity['target'].mean() * 100
            percentile_fraud.append(fraud_rate)
        else:
            percentile_fraud.append(0)

    ax2.plot(percentiles, percentile_fraud, 'o-', linewidth=2, markersize=4)
    ax2.set_title('Fraud Rate –ø–æ —É—Ä–æ–≤–Ω—é –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏', fontsize=14)
    ax2.set_xlabel('–£—Ä–æ–≤–µ–Ω—å –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ (–ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª—å)', fontsize=12)
    ax2.set_ylabel('Fraud Rate (%)', fontsize=12)
    ax2.grid(True, alpha=0.3)

    # –î–æ–±–∞–≤–ª—è–µ–º –∫–ª—é—á–µ–≤—ã–µ —Ç–æ—á–∫–∏
    key_percentiles = [5, 25, 50, 75, 95]
    for p in key_percentiles:
        closest_p = min(percentiles, key=lambda x: abs(x - p))
        idx = list(percentiles).index(closest_p)
        actual_activity = np.percentile(df['activity_level'], p)

        ax2.annotate(f'{p}%: {percentile_fraud[idx]:.1f}%\n(–∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å‚â•{actual_activity:.1f})',
                     (p, percentile_fraud[idx]),
                     xytext=(10, 5), textcoords='offset points',
                     bbox=dict(boxstyle='round,pad=0.3', facecolor='yellow', alpha=0.7),
                     fontsize=9)

    plt.tight_layout()
    plt.show()

    # –ê–Ω–∞–ª–∏–∑ —Å–∞–º—ã—Ö –∞–∫—Ç–∏–≤–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
    print("\nüìä –ê–ù–ê–õ–ò–ó –°–ê–ú–´–• –ê–ö–¢–ò–í–ù–´–• –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–ï–ô:")
    for p in [90, 95, 99]:
        threshold = np.percentile(df['activity_level'], p)
        active_users = df[df['activity_level'] >= threshold]
        if len(active_users) > 0:
            fraud_rate = active_users['target'].mean() * 100
            interval = 30 - threshold  # –ø–µ—Ä–µ–≤–æ–¥–∏–º –æ–±—Ä–∞—Ç–Ω–æ –≤ –∏–Ω—Ç–µ—Ä–≤–∞–ª
            print(
                f"–¢–æ–ø {100 - p}% (–∏–Ω—Ç–µ—Ä–≤–∞–ª‚â§{interval:.1f}–¥–Ω): {len(active_users)} –∑–∞–ø–∏—Å–µ–π, Fraud Rate: {fraud_rate:.2f}%")

    return outliers


def nonlinear_analysis(df):
    """–ü–æ–∏—Å–∫ –Ω–µ–ª–∏–Ω–µ–π–Ω—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π –¥–ª—è avg_login_interval_30d."""

    print("\n" + "=" * 60)
    print("4. –ü–û–ò–°–ö –ù–ï–õ–ò–ù–ï–ô–ù–´–• –ó–ê–í–ò–°–ò–ú–û–°–¢–ï–ô")
    print("=" * 60)

    # –°–æ–∑–¥–∞–µ–º –∫–æ–ø–∏—é –¥–∞–Ω–Ω—ã—Ö –∏ —Å–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –∏–Ω—Ç–µ—Ä–≤–∞–ª—É
    sorted_df = df.copy().sort_values('interval_processed').reset_index(drop=True)

    # –ê–¥–∞–ø—Ç–∏–≤–Ω–æ–µ –æ–∫–Ω–æ –¥–ª—è —Å–∫–æ–ª—å–∑—è—â–µ–≥–æ —Å—Ä–µ–¥–Ω–µ–≥–æ
    window_size = min(100, len(df) // 10)
    sorted_df['rolling_fraud'] = sorted_df['target'].rolling(window=window_size, center=True).mean()

    # –£–¥–∞–ª—è–µ–º —Å—Ç—Ä–æ–∫–∏ —Å NaN –≤ rolling_fraud
    valid_data = sorted_df.dropna(subset=['rolling_fraud']).copy()

    # –ü–æ–ª–∏–Ω–æ–º–∏–∞–ª—å–Ω–∞—è –∞–ø–ø—Ä–æ–∫—Å–∏–º–∞—Ü–∏—è
    X_poly = valid_data['interval_processed'].values
    Y_poly = valid_data['rolling_fraud'].values

    # –ê–ø–ø—Ä–æ–∫—Å–∏–º–∞—Ü–∏–∏ —Ä–∞–∑–Ω–æ–π —Å—Ç–µ–ø–µ–Ω–∏
    degrees = [1, 2, 3, 4]
    colors = ['red', 'blue', 'green', 'purple']

    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))

    # –ì—Ä–∞—Ñ–∏–∫ 1: –°–∫–æ–ª—å–∑—è—â–µ–µ —Å—Ä–µ–¥–Ω–µ–µ
    ax1.scatter(sorted_df['interval_processed'], sorted_df['target'],
                alpha=0.1, color='gray', s=1, label='–ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ')
    ax1.plot(valid_data['interval_processed'], valid_data['rolling_fraud'] * 100,
             linewidth=3, color='black', label=f'–°–∫–æ–ª—å–∑—è—â–µ–µ —Å—Ä–µ–¥–Ω–µ–µ (n={window_size})')
    ax1.set_title('Fraud Rate vs –ò–Ω—Ç–µ—Ä–≤–∞–ª –º–µ–∂–¥—É –ª–æ–≥–∏–Ω–∞–º–∏\n(—Å–∫–æ–ª—å–∑—è—â–µ–µ —Å—Ä–µ–¥–Ω–µ–µ)', fontsize=14)
    ax1.set_xlabel('–ò–Ω—Ç–µ—Ä–≤–∞–ª –º–µ–∂–¥—É –ª–æ–≥–∏–Ω–∞–º–∏ (–¥–Ω–∏)', fontsize=12)
    ax1.set_ylabel('Fraud Rate (%)', fontsize=12)
    ax1.set_xlim(0, 30)  # –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑—É–º–Ω—ã–º –¥–∏–∞–ø–∞–∑–æ–Ω–æ–º
    ax1.legend()
    ax1.grid(True, alpha=0.3)

    # –ì—Ä–∞—Ñ–∏–∫ 2: –ü–æ–ª–∏–Ω–æ–º–∏–∞–ª—å–Ω–∞—è –∞–ø–ø—Ä–æ–∫—Å–∏–º–∞—Ü–∏—è
    ax2.scatter(X_poly, Y_poly * 100, alpha=0.3, color='gray', s=10, label='–°–≥–ª–∞–∂–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ')

    r_squared = {}
    for degree, color in zip(degrees, colors):
        try:
            coeffs = np.polyfit(X_poly, Y_poly, degree)
            polynomial = np.poly1d(coeffs)
            y_fit = polynomial(X_poly)

            # R¬≤
            ss_res = np.sum((Y_poly - y_fit) ** 2)
            ss_tot = np.sum((Y_poly - np.mean(Y_poly)) ** 2)
            r_sq = 1 - (ss_res / ss_tot) if ss_tot != 0 else 0
            r_squared[degree] = r_sq

            ax2.plot(X_poly, y_fit * 100, color=color, linewidth=2,
                     label=f'–ü–æ–ª–∏–Ω–æ–º {degree} —Å—Ç–µ–ø–µ–Ω–∏ (R¬≤={r_sq:.3f})')
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–ø–ø—Ä–æ–∫—Å–∏–º–∞—Ü–∏–∏ —Å—Ç–µ–ø–µ–Ω–∏ {degree}: {e}")
            r_squared[degree] = 0

    ax2.set_title('–ü–æ–ª–∏–Ω–æ–º–∏–∞–ª—å–Ω–∞—è –∞–ø–ø—Ä–æ–∫—Å–∏–º–∞—Ü–∏—è', fontsize=14)
    ax2.set_xlabel('–ò–Ω—Ç–µ—Ä–≤–∞–ª –º–µ–∂–¥—É –ª–æ–≥–∏–Ω–∞–º–∏ (–¥–Ω–∏)', fontsize=12)
    ax2.set_ylabel('Fraud Rate (%)', fontsize=12)
    ax2.set_xlim(0, 30)
    ax2.legend()
    ax2.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.show()

    # –ê–Ω–∞–ª–∏–∑ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π —Å—Ç–µ–ø–µ–Ω–∏
    print("üìä –ö–ê–ß–ï–°–¢–í–û –ê–ü–ü–†–û–ö–°–ò–ú–ê–¶–ò–ò:")
    for degree, r_sq in r_squared.items():
        print(f"–ü–æ–ª–∏–Ω–æ–º {degree} —Å—Ç–µ–ø–µ–Ω–∏: R¬≤ = {r_sq:.4f}")

    # –õ–æ–∫–∞–ª—å–Ω—ã–µ –º–∞–∫—Å–∏–º—É–º—ã/–º–∏–Ω–∏–º—É–º—ã –¥–ª—è –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
    if r_squared:
        optimal_degree = max(r_squared, key=r_squared.get)
        try:
            coeffs = np.polyfit(X_poly, Y_poly, optimal_degree)
            polynomial = np.poly1d(coeffs)

            # –ü—Ä–æ–∏–∑–≤–æ–¥–Ω–∞—è –¥–ª—è –ø–æ–∏—Å–∫–∞ —ç–∫—Å—Ç—Ä–µ–º—É–º–æ–≤
            derivative = polynomial.deriv()
            critical_points = derivative.roots

            # –§–∏–ª—å—Ç—Ä—É–µ–º –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–µ —Ç–æ—á–∫–∏ –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ –¥–∞–Ω–Ω—ã—Ö
            real_critical_points = critical_points[np.isreal(critical_points)].real
            real_critical_points = real_critical_points[
                (real_critical_points >= X_poly.min()) &
                (real_critical_points <= X_poly.max())
                ]

            print(f"\nüîç –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ï –¢–û–ß–ö–ò (–ø–æ–ª–∏–Ω–æ–º {optimal_degree} —Å—Ç–µ–ø–µ–Ω–∏):")
            if len(real_critical_points) > 0:
                for point in real_critical_points:
                    fraud_at_point = polynomial(point) * 100
                    point_type = "–ú–ê–ö–°–ò–ú–£–ú" if polynomial.deriv(2)(point) < 0 else "–º–∏–Ω–∏–º—É–º"
                    print(f"  {point:.1f} –¥–Ω–µ–π: Fraud Rate = {fraud_at_point:.2f}% ({point_type})")
            else:
                print("  –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ —Ç–æ—á–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")

        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö —Ç–æ—á–µ–∫: {e}")

    return r_squared


def kde_analysis(df):
    """Kernel Density Estimation –¥–ª—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–≤."""

    print("\n" + "=" * 60)
    print("5. KERNEL DENSITY ESTIMATION")
    print("=" * 60)

    # –ò–°–ü–û–õ–¨–ó–£–ï–ú –û–ë–†–ê–ë–û–¢–ê–ù–ù–´–ï –î–ê–ù–ù–´–ï
    interval_0 = df[df['target'] == 0]['interval_processed']
    interval_1 = df[df['target'] == 1]['interval_processed']

    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–∏–∞–ø–∞–∑–æ–Ω –¥–ª—è –ª—É—á—à–µ–π –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
    max_val = 30  # –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª –≤ –¥–Ω—è—Ö
    interval_0_trimmed = interval_0[interval_0 <= max_val]
    interval_1_trimmed = interval_1[interval_1 <= max_val]

    print(f"–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è KDE –¥–ª—è –¥–∏–∞–ø–∞–∑–æ–Ω–∞ 0-{max_val} –¥–Ω–µ–π")
    print(f"–û—Ö–≤–∞—Ç—ã–≤–∞–µ—Ç {len(interval_0_trimmed) / len(interval_0) * 100:.1f}% –ª–µ–≥–∏—Ç–∏–º–Ω—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π")
    print(f"–û—Ö–≤–∞—Ç—ã–≤–∞–µ—Ç {len(interval_1_trimmed) / len(interval_1) * 100:.1f}% –º–æ—à–µ–Ω–Ω–∏—á–µ—Å–∫–∏—Ö –æ–ø–µ—Ä–∞—Ü–∏–π")

    # KDE —Å —Ä–∞–∑–Ω—ã–º–∏ bandwidth
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))

    bandwidths = [0.5, 1.0, 2.0, 'auto']
    titles = ['Small bandwidth (0.5)', 'Medium bandwidth (1.0)',
              'Large bandwidth (2.0)', 'Auto bandwidth']

    for idx, (bw, title) in enumerate(zip(bandwidths, titles)):
        ax = axes[idx // 2, idx % 2]

        # KDE –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞
        if bw == 'auto':
            kde_0 = stats.gaussian_kde(interval_0_trimmed)
            kde_1 = stats.gaussian_kde(interval_1_trimmed)
        else:
            kde_0 = stats.gaussian_kde(interval_0_trimmed, bw_method=bw)
            kde_1 = stats.gaussian_kde(interval_1_trimmed, bw_method=bw)

        x_range = np.linspace(0, max_val, 200)

        ax.plot(x_range, kde_0(x_range), label='Target=0 (–õ–µ–≥–∏—Ç–∏–º–Ω—ã–µ)',
                color='blue', linewidth=2)
        ax.plot(x_range, kde_1(x_range), label='Target=1 (–ú–æ—à–µ–Ω–Ω–∏—á–µ—Å–∫–∏–µ)',
                color='red', linewidth=2)

        ax.set_title(f'KDE: {title}', fontsize=14)
        ax.set_xlabel('–ò–Ω—Ç–µ—Ä–≤–∞–ª –º–µ–∂–¥—É –ª–æ–≥–∏–Ω–∞–º–∏ (–¥–Ω–∏)', fontsize=12)
        ax.set_ylabel('–ü–ª–æ—Ç–Ω–æ—Å—Ç—å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏', fontsize=12)
        ax.legend()
        ax.grid(True, alpha=0.3)
        ax.set_xlim(0, max_val)

    plt.tight_layout()
    plt.show()

    # Ratio of densities (—Å–∏–≥–Ω–∞–ª –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏)
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))

    # Auto KDE –¥–ª—è ratio –∞–Ω–∞–ª–∏–∑–∞
    kde_0_auto = stats.gaussian_kde(interval_0_trimmed)
    kde_1_auto = stats.gaussian_kde(interval_1_trimmed)

    x_range = np.linspace(0, max_val, 200)
    density_0 = kde_0_auto(x_range)
    density_1 = kde_1_auto(x_range)

    # –û—Ç–Ω–æ—à–µ–Ω–∏–µ –ø–ª–æ—Ç–Ω–æ—Å—Ç–µ–π
    likelihood_ratio = np.where(density_0 > 0, density_1 / density_0, 0)

    ax1.plot(x_range, density_0, label='P(x|Target=0)', color='blue', linewidth=2)
    ax1.plot(x_range, density_1, label='P(x|Target=1)', color='red', linewidth=2)
    ax1.set_title('–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–Ω—ã–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è', fontsize=14)
    ax1.set_xlabel('–ò–Ω—Ç–µ—Ä–≤–∞–ª –º–µ–∂–¥—É –ª–æ–≥–∏–Ω–∞–º–∏ (–¥–Ω–∏)', fontsize=12)
    ax1.set_ylabel('–ü–ª–æ—Ç–Ω–æ—Å—Ç—å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏', fontsize=12)
    ax1.legend()
    ax1.grid(True, alpha=0.3)

    ax2.plot(x_range, likelihood_ratio, color='purple', linewidth=3)
    ax2.axhline(y=1, color='black', linestyle='--', alpha=0.5, label='–ü–æ—Ä–æ–≥ (ratio=1)')
    ax2.set_title('Likelihood Ratio: P(x|Target=1) / P(x|Target=0)', fontsize=14)
    ax2.set_xlabel('–ò–Ω—Ç–µ—Ä–≤–∞–ª –º–µ–∂–¥—É –ª–æ–≥–∏–Ω–∞–º–∏ (–¥–Ω–∏)', fontsize=12)
    ax2.set_ylabel('Likelihood Ratio', fontsize=12)
    ax2.legend()
    ax2.grid(True, alpha=0.3)

    # –û–±–ª–∞—Å—Ç–∏ –≥–¥–µ –º–æ—à–µ–Ω–Ω–∏–∫–∏ –±–æ–ª–µ–µ –≤–µ—Ä–æ—è—Ç–Ω—ã
    fraud_preferred = x_range[likelihood_ratio > 1]
    if len(fraud_preferred) > 0:
        print(f"üîç –û–ë–õ–ê–°–¢–ò –ü–†–ï–ò–ú–£–©–ï–°–¢–í–ê –ú–û–®–ï–ù–ù–ò–ö–û–í:")
        print(f"  –ò–Ω—Ç–µ—Ä–≤–∞–ª –æ—Ç {fraud_preferred[0]:.1f} –¥–æ {fraud_preferred[-1]:.1f} –¥–Ω–µ–π")

        # –ü–∏–∫ –æ—Ç–Ω–æ—à–µ–Ω–∏—è –ø—Ä–∞–≤–¥–æ–ø–æ–¥–æ–±–∏—è
        peak_idx = np.argmax(likelihood_ratio)
        peak_x = x_range[peak_idx]
        peak_ratio = likelihood_ratio[peak_idx]
        print(f"  –ü–∏–∫ –æ—Ç–Ω–æ—à–µ–Ω–∏—è: {peak_ratio:.2f} –ø—Ä–∏ {peak_x:.1f} –¥–Ω—è—Ö")

    plt.tight_layout()
    plt.show()

    return likelihood_ratio, x_range


def final_report(df, trend_data, r_squared, likelihood_ratio, x_range):
    """–§–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç —Å –≤—ã–≤–æ–¥–∞–º–∏ –¥–ª—è avg_login_interval_30d."""

    print("\n" + "=" * 80)
    print("üéØ –ò–¢–û–ì–û–í–´–ô –û–¢–ß–ï–¢ –ê–ù–ê–õ–ò–ó–ê (avg_login_interval_30d)")
    print("=" * 80)

    # –ö–ª—é—á–µ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
    total_fraud_rate = df['target'].mean() * 100
    correlation = df['interval_processed'].corr(df['target'])

    print("üìà –ö–õ–Æ–ß–ï–í–´–ï –ú–ï–¢–†–ò–ö–ò:")
    print(f"  ‚Ä¢ –û–±—â–∏–π Fraud Rate: {total_fraud_rate:.2f}%")
    print(f"  ‚Ä¢ –ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è –∏–Ω—Ç–µ—Ä–≤–∞–ª-—Ä–∏—Å–∫: {correlation:.4f}")
    print(f"  ‚Ä¢ –û–ø—Ç–∏–º–∞–ª—å–Ω–∞—è —Å—Ç–µ–ø–µ–Ω—å –ø–æ–ª–∏–Ω–æ–º–∞: {max(r_squared, key=r_squared.get)}")
    print(f"  ‚Ä¢ –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π likelihood ratio: {np.max(likelihood_ratio):.2f}")

    # –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    print("\nüí° –ü–†–ê–ö–¢–ò–ß–ï–°–ö–ò–ï –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")

    # –ê–Ω–∞–ª–∏–∑ –∫–ª—é—á–µ–≤—ã—Ö –≥—Ä—É–ø–ø
    very_active = df[df['interval_processed'] <= 1]  # –µ–∂–µ–¥–Ω–µ–≤–Ω–æ
    active = df[(df['interval_processed'] > 1) & (df['interval_processed'] <= 7)]  # —Ä–∞–∑ –≤ –Ω–µ–¥–µ–ª—é
    inactive = df[df['interval_processed'] > 14]  # —Ä–µ–∂–µ —á–µ–º —Ä–∞–∑ –≤ 2 –Ω–µ–¥–µ–ª–∏

    print(f"  1. –û–ß–ï–ù–¨ –ê–ö–¢–ò–í–ù–´–ï (–∏–Ω—Ç–µ—Ä–≤–∞–ª ‚â§ 1 –¥–µ–Ω—å):")
    print(f"     ‚Ä¢ {len(very_active)} –∑–∞–ø–∏—Å–µ–π ({len(very_active) / len(df) * 100:.1f}%)")
    print(f"     ‚Ä¢ Fraud Rate: {very_active['target'].mean() * 100:.2f}%")

    print(f"  2. –ê–ö–¢–ò–í–ù–´–ï (1-7 –¥–Ω–µ–π):")
    print(f"     ‚Ä¢ {len(active)} –∑–∞–ø–∏—Å–µ–π ({len(active) / len(df) * 100:.1f}%)")
    print(f"     ‚Ä¢ Fraud Rate: {active['target'].mean() * 100:.2f}%")

    print(f"  3. –ù–ï–ê–ö–¢–ò–í–ù–´–ï (>14 –¥–Ω–µ–π):")
    print(f"     ‚Ä¢ {len(inactive)} –∑–∞–ø–∏—Å–µ–π ({len(inactive) / len(df) * 100:.1f}%)")
    print(f"     ‚Ä¢ Fraud Rate: {inactive['target'].mean() * 100:.2f}%")

    # –û–±–ª–∞—Å—Ç–∏ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ —Å–∏–≥–Ω–∞–ª–∞
    peak_signal_idx = np.argmax(likelihood_ratio)
    peak_signal_x = x_range[peak_signal_idx]

    print(f"  4. –ú–ê–ö–°–ò–ú–ê–õ–¨–ù–´–ô –°–ò–ì–ù–ê–õ:")
    print(f"     ‚Ä¢ {peak_signal_x:.1f} –¥–Ω–µ–π (likelihood ratio = {np.max(likelihood_ratio):.2f})")

    # –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∞—è –∑–Ω–∞—á–∏–º–æ—Å—Ç—å
    from scipy.stats import mannwhitneyu
    interval_0 = df[df['target'] == 0]['interval_processed']
    interval_1 = df[df['target'] == 1]['interval_processed']

    stat, p_value = mannwhitneyu(interval_0, interval_1, alternative='two-sided')

    print(f"\nüìä –°–¢–ê–¢–ò–°–¢–ò–ß–ï–°–ö–ê–Ø –ó–ù–ê–ß–ò–ú–û–°–¢–¨:")
    print(f"  ‚Ä¢ –¢–µ—Å—Ç –ú–∞–Ω–Ω–∞-–£–∏—Ç–Ω–∏: p-value = {p_value:.6f}")
    print(f"  ‚Ä¢ –†–∞–∑–ª–∏—á–∏–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π: {'–ó–ù–ê–ß–ò–ú–û' if p_value < 0.05 else '–ù–ï–ó–ù–ê–ß–ò–ú–û'}")

    # –§–∏–Ω–∞–ª—å–Ω–∞—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
    plt.figure(figsize=(12, 8))

    # –ö–æ–º–ø–æ–∑–∏—Ç–Ω—ã–π –≥—Ä–∞—Ñ–∏–∫
    plt.subplot(2, 1, 1)

    # KDE —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è
    max_kde = 30
    interval_0_trimmed = interval_0[interval_0 <= max_kde]
    interval_1_trimmed = interval_1[interval_1 <= max_kde]

    kde_0 = stats.gaussian_kde(interval_0_trimmed)
    kde_1 = stats.gaussian_kde(interval_1_trimmed)
    x_kde = np.linspace(0, max_kde, 200)

    plt.plot(x_kde, kde_0(x_kde), label='–õ–µ–≥–∏—Ç–∏–º–Ω—ã–µ (Target=0)', color='blue', linewidth=2)
    plt.plot(x_kde, kde_1(x_kde), label='–ú–æ—à–µ–Ω–Ω–∏—á–µ—Å–∫–∏–µ (Target=1)', color='red', linewidth=2)
    plt.title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–≤ –º–µ–∂–¥—É –ª–æ–≥–∏–Ω–∞–º–∏', fontsize=16, fontweight='bold')
    plt.xlabel('–ò–Ω—Ç–µ—Ä–≤–∞–ª –º–µ–∂–¥—É –ª–æ–≥–∏–Ω–∞–º–∏ (–¥–Ω–∏)', fontsize=12)
    plt.ylabel('–ü–ª–æ—Ç–Ω–æ—Å—Ç—å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏', fontsize=12)
    plt.legend()
    plt.grid(True, alpha=0.3)

    plt.subplot(2, 1, 2)

    # Fraud rate —Ç—Ä–µ–Ω–¥
    plt.plot(trend_data.index, trend_data['fraud_rate_pct'], 'o-',
             linewidth=3, markersize=8, color='green', label='–ù–∞–±–ª—é–¥–∞–µ–º—ã–π Fraud Rate')
    plt.axhline(y=total_fraud_rate, color='black', linestyle='--',
                label=f'–û–±—â–∏–π Fraud Rate ({total_fraud_rate:.2f}%)')
    plt.title('Fraud Rate –ø–æ —É—Ä–æ–≤–Ω—è–º –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏', fontsize=14)
    plt.xlabel('–£—Ä–æ–≤–µ–Ω—å –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏', fontsize=12)
    plt.ylabel('Fraud Rate (%)', fontsize=12)
    plt.xticks(rotation=45)
    plt.legend()
    plt.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.show()

    print("\n‚úÖ –ê–ù–ê–õ–ò–ó –ó–ê–í–ï–†–®–ï–ù!")


def analyze_manual_bins(df, feature, target, bins, bin_labels=None):
    """
    –í—ã–ø–æ–ª–Ω—è–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ —Ä—É—á–Ω—ã—Ö –±–∏–Ω–æ–≤ –¥–ª—è fraud detection.

    Parameters:
    -----------
    df : pandas.DataFrame
        –ò—Å—Ö–æ–¥–Ω—ã–π –¥–∞—Ç–∞—Ñ—Ä–µ–π–º
    feature : str
        –ù–∞–∑–≤–∞–Ω–∏–µ —á–∏—Å–ª–æ–≤–æ–π –∫–æ–ª–æ–Ω–∫–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä 'login_frequency_7d')
    target : str
        –ö–æ–ª–æ–Ω–∫–∞ —Å —Ç–∞—Ä–≥–µ—Ç–æ–º (0/1)
    bins : list
        –°–ø–∏—Å–æ–∫ –≥—Ä–∞–Ω–∏—Ü –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–≤, –Ω–∞–ø—Ä–∏–º–µ—Ä: [0, 0.5, 1, 2, 3, 5, 8, 100]
    bin_labels : list, optional
        –ù–∞–∑–≤–∞–Ω–∏—è –±–∏–Ω–æ–≤. –ï—Å–ª–∏ None, –≥–µ–Ω–µ—Ä–∏—Ä—É—é—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏

    Returns:
    --------
    pandas.DataFrame
        –¢–∞–±–ª–∏—Ü–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫ –ø–æ –∫–∞–∂–¥–æ–º—É –±–∏–Ω—É —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏
    """

    # –ö–æ–ø–∏—Ä—É–µ–º –¥–∞—Ç–∞—Ñ—Ä–µ–π–º —á—Ç–æ–±—ã –Ω–µ –º–æ–¥–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å –æ—Ä–∏–≥–∏–Ω–∞–ª
    df_work = df.copy()

    # –ë–∞–∑–æ–≤—ã–π fraud rate –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ RRN
    baseline_fraud_rate = df_work[target].mean()

    # –ü—Ä–∏—Å–≤–∞–∏–≤–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏—è–º –±–∏–Ω
    df_work['bin'] = pd.cut(
        df_work[feature],
        bins=bins,
        labels=bin_labels,
        include_lowest=True,
        right=False  # [a, b) - –ø—Ä–∞–≤–∞—è –≥—Ä–∞–Ω–∏—Ü–∞ –Ω–µ –≤–∫–ª—é—á–∞–µ—Ç—Å—è
    )

    # –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ –±–∏–Ω–∞–º
    groups = df_work.groupby('bin', observed=True)

    # –°–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞
    result = []

    for bin_name, group in groups:

        values = group[feature].values

        # –ó–∞—â–∏—Ç–∞ –æ—Ç –ø—É—Å—Ç—ã—Ö –±–∏–Ω–æ–≤
        if len(values) == 0:
            result.append({
                'bin': bin_name,
                'count': 0,
                'fraud_count': 0,
                'fraud_rate': 0,
                'RRN': np.nan,
                'SE': np.nan,
                'CI_lower': np.nan,
                'CI_upper': np.nan,
                'CI_width': np.nan,
                'reliability': 'NO_DATA',
                'mean': np.nan,
                'median': np.nan,
                'std': np.nan,
                'CV%': np.nan,
                'Q25': np.nan,
                'Q75': np.nan,
                'IQR': np.nan,
                'pct_nonzero': np.nan
            })
            continue

        # === –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ï –ú–ï–¢–†–ò–ö–ò –î–õ–Ø FRAUD DETECTION ===

        count = len(values)
        fraud_count = group[target].sum()
        fraud_rate = fraud_count / count if count > 0 else 0

        # üî¥ –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï 1: RRN = –æ—Ç–Ω–æ—à–µ–Ω–∏–µ fraud rates, –∞ –Ω–µ –∫–≤–∞—Ä—Ç–∏–ª–µ–π!
        # RRN (Relative Risk Ratio) - –≤–æ —Å–∫–æ–ª—å–∫–æ —Ä–∞–∑ —Ä–∏—Å–∫ –æ—Ç–ª–∏—á–∞–µ—Ç—Å—è –æ—Ç baseline
        RRN = fraud_rate / baseline_fraud_rate if baseline_fraud_rate > 0 else np.nan

        # üî¥ –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï 2: SE –¥–ª—è –±–∏–Ω–æ–º–∏–∞–ª—å–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è (fraud rate)
        # Standard Error –¥–ª—è –ø—Ä–æ–ø–æ—Ä—Ü–∏–∏
        SE_fraud = np.sqrt(fraud_rate * (1 - fraud_rate) / count) if count > 0 else np.nan

        # 95% Confidence Interval –¥–ª—è fraud rate
        CI_lower = max(0, fraud_rate - 1.96 * SE_fraud) if not np.isnan(SE_fraud) else np.nan
        CI_upper = min(1, fraud_rate + 1.96 * SE_fraud) if not np.isnan(SE_fraud) else np.nan
        CI_width = CI_upper - CI_lower if not np.isnan(CI_lower) else np.nan

        # –û—Ü–µ–Ω–∫–∞ –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏ –±–∏–Ω–∞
        if count >= 500 and CI_width < 0.03:
            reliability = 'HIGH'
        elif count >= 200 and CI_width < 0.05:
            reliability = 'MEDIUM'
        elif count >= 50:
            reliability = 'LOW'
        else:
            reliability = 'VERY_LOW'

        # === –î–ï–°–ö–†–ò–ü–¢–ò–í–ù–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–†–ò–ó–ù–ê–ö–ê ===

        mean = np.mean(values)
        median = np.median(values)
        std = np.std(values, ddof=1) if count > 1 else 0

        # SE –¥–ª—è —Å—Ä–µ–¥–Ω–µ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–∞ (–Ω–µ fraud rate!)
        SE_mean = std / np.sqrt(count) if count > 1 else 0

        # Coefficient of Variation
        CV = (std / mean * 100) if mean != 0 else 0

        Q25 = np.percentile(values, 25)
        Q75 = np.percentile(values, 75)
        IQR = Q75 - Q25  # Interquartile Range

        # –ü—Ä–æ—Ü–µ–Ω—Ç –Ω–µ–Ω—É–ª–µ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
        pct_nonzero = (values != 0).sum() / count * 100 if count > 0 else 0

        result.append({
            # –ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è –±–∏–Ω–∞
            'bin': str(bin_name),

            # === FRAUD –ú–ï–¢–†–ò–ö–ò (–ö–†–ò–¢–ò–ß–ù–û!) ===
            'count': count,
            'fraud_count': int(fraud_count),
            'fraud_rate': round(fraud_rate * 100, 3),  # –≤ –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö
            'RRN': round(RRN, 3),  # ‚úÖ –ü–†–ê–í–ò–õ–¨–ù–´–ô RRN
            'SE': round(SE_fraud * 100, 3),  # ‚úÖ SE –¥–ª—è fraud rate (–≤ –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö)
            'CI_lower': round(CI_lower * 100, 3),  # –≤ –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö
            'CI_upper': round(CI_upper * 100, 3),  # –≤ –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö
            'CI_width': round(CI_width * 100, 3),  # –≤ –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö
            'reliability': reliability,

            # === –î–ï–°–ö–†–ò–ü–¢–ò–í–ù–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê ===
            'mean': round(mean, 3),
            'median': round(median, 3),
            'std': round(std, 3),
            'SE_mean': round(SE_mean, 3),  # SE –¥–ª—è —Å—Ä–µ–¥–Ω–µ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–∞
            'CV%': round(CV, 2),
            'Q25': round(Q25, 3),
            'Q75': round(Q75, 3),
            'IQR': round(IQR, 3),
            'pct_nonzero': round(pct_nonzero, 2)
        })

    result_df = pd.DataFrame(result)

    # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –ø–æ—Ä—è–¥–∫—É –±–∏–Ω–æ–≤ (–µ—Å–ª–∏ bin - –∫–∞—Ç–µ–≥–æ—Ä–∏—è —Å –ø–æ—Ä—è–¥–∫–æ–º)
    if bin_labels is not None:
        result_df['bin'] = pd.Categorical(result_df['bin'], categories=bin_labels, ordered=True)
        result_df = result_df.sort_values('bin')

    return result_df

def visualize_bin_analysis(analysis_df, feature_name):
    """
    –í—ã–≤–æ–¥–∏—Ç –∫—Ä–∞—Å–∏–≤—É—é –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞ –±–∏–Ω–æ–≤
    """
    import matplotlib.pyplot as plt
    import seaborn as sns

    print("=" * 80)
    print(f"üìä –ê–ù–ê–õ–ò–ó –ü–†–ò–ó–ù–ê–ö–ê: {feature_name}")
    print("=" * 80)

    # –û—Å–Ω–æ–≤–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞
    print("\nüéØ FRAUD –ú–ï–¢–†–ò–ö–ò –ü–û –ë–ò–ù–ê–ú:\n")
    display_cols = ['bin', 'count', 'fraud_count', 'fraud_rate', 'RRN',
                    'CI_width', 'reliability']
    print(analysis_df[display_cols].to_string(index=False))

    # –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è –æ –Ω–µ–Ω–∞–¥–µ–∂–Ω—ã—Ö –±–∏–Ω–∞—Ö
    unreliable = analysis_df[analysis_df['reliability'].isin(['LOW', 'VERY_LOW'])]
    if len(unreliable) > 0:
        print("\n‚ö†Ô∏è  –í–ù–ò–ú–ê–ù–ò–ï: –ù–µ–Ω–∞–¥–µ–∂–Ω—ã–µ –±–∏–Ω—ã (—Ç—Ä–µ–±—É—é—Ç –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è):")
        print(unreliable[['bin', 'count', 'fraud_rate', 'CI_width', 'reliability']].to_string(index=False))

    # –í—ã–≤–æ–¥—ã
    print("\n‚úÖ –í–´–í–û–î–´:")

    high_risk = analysis_df[
        (analysis_df['RRN'] >= 1.5) &
        (analysis_df['reliability'].isin(['HIGH', 'MEDIUM']))
        ]
    if len(high_risk) > 0:
        print(f"\nüî¥ –ë–∏–Ω—ã —Å –ü–û–í–´–®–ï–ù–ù–´–ú —Ä–∏—Å–∫–æ–º (RRN ‚â• 1.5, –Ω–∞–¥–µ–∂–Ω—ã–µ):")
        for _, row in high_risk.iterrows():
            print(f"   ‚Ä¢ {row['bin']}: FR={row['fraud_rate']:.2f}%, RRN={row['RRN']:.2f}, n={row['count']}")

    low_risk = analysis_df[
        (analysis_df['RRN'] <= 0.7) &
        (analysis_df['reliability'].isin(['HIGH', 'MEDIUM']))
        ]
    if len(low_risk) > 0:
        print(f"\nüü¢ –ë–∏–Ω—ã —Å –ü–û–ù–ò–ñ–ï–ù–ù–´–ú —Ä–∏—Å–∫–æ–º (RRN ‚â§ 0.7, –Ω–∞–¥–µ–∂–Ω—ã–µ):")
        for _, row in low_risk.iterrows():
            print(f"   ‚Ä¢ {row['bin']}: FR={row['fraud_rate']:.2f}%, RRN={row['RRN']:.2f}, n={row['count']}")

    # –ì—Ä–∞—Ñ–∏–∫
    fig, axes = plt.subplots(2, 2, figsize=(14, 10))

    # 1. Fraud Rate —Å –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–º–∏ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞–º–∏
    ax1 = axes[0, 0]
    reliable = analysis_df[analysis_df['reliability'].isin(['HIGH', 'MEDIUM'])]
    unreliable = analysis_df[~analysis_df['reliability'].isin(['HIGH', 'MEDIUM'])]

    ax1.bar(range(len(reliable)), reliable['fraud_rate'],
            color='steelblue', alpha=0.7, label='–ù–∞–¥–µ–∂–Ω—ã–µ')
    ax1.bar(range(len(reliable), len(analysis_df)), unreliable['fraud_rate'],
            color='lightcoral', alpha=0.5, label='–ù–µ–Ω–∞–¥–µ–∂–Ω—ã–µ')

    # –î–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã
    for i, row in analysis_df.iterrows():
        ax1.errorbar(i, row['fraud_rate'],
                     yerr=row['CI_width'] / 2,
                     fmt='none', color='black', capsize=5, alpha=0.5)

    ax1.set_xlabel('Bin')
    ax1.set_ylabel('Fraud Rate (%)')
    ax1.set_title('Fraud Rate –ø–æ –±–∏–Ω–∞–º —Å 95% CI')
    ax1.set_xticks(range(len(analysis_df)))
    ax1.set_xticklabels(analysis_df['bin'], rotation=45, ha='right')
    ax1.legend()
    ax1.grid(axis='y', alpha=0.3)

    # 2. RRN
    ax2 = axes[0, 1]
    colors = ['green' if r <= 0.7 else 'red' if r >= 1.5 else 'gray'
              for r in analysis_df['RRN']]
    ax2.bar(range(len(analysis_df)), analysis_df['RRN'], color=colors, alpha=0.7)
    ax2.axhline(y=1.0, color='black', linestyle='--', label='Baseline (RRN=1.0)')
    ax2.axhline(y=1.5, color='red', linestyle=':', alpha=0.5, label='High Risk (1.5)')
    ax2.axhline(y=0.7, color='green', linestyle=':', alpha=0.5, label='Low Risk (0.7)')
    ax2.set_xlabel('Bin')
    ax2.set_ylabel('RRN (Relative Risk Ratio)')
    ax2.set_title('–û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π —Ä–∏—Å–∫ –ø–æ –±–∏–Ω–∞–º')
    ax2.set_xticks(range(len(analysis_df)))
    ax2.set_xticklabels(analysis_df['bin'], rotation=45, ha='right')
    ax2.legend()
    ax2.grid(axis='y', alpha=0.3)

    # 3. –†–∞–∑–º–µ—Ä –≤—ã–±–æ—Ä–∫–∏ –∏ –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç—å
    ax3 = axes[1, 0]
    reliability_colors = {
        'HIGH': 'green',
        'MEDIUM': 'orange',
        'LOW': 'red',
        'VERY_LOW': 'darkred',
        'NO_DATA': 'gray'
    }
    colors = [reliability_colors.get(r, 'gray') for r in analysis_df['reliability']]
    ax3.bar(range(len(analysis_df)), analysis_df['count'], color=colors, alpha=0.7)
    ax3.axhline(y=500, color='green', linestyle='--', alpha=0.5, label='High reliability (500)')
    ax3.axhline(y=200, color='orange', linestyle='--', alpha=0.5, label='Medium reliability (200)')
    ax3.set_xlabel('Bin')
    ax3.set_ylabel('Sample Size')
    ax3.set_title('–†–∞–∑–º–µ—Ä –≤—ã–±–æ—Ä–∫–∏ –∏ –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç—å')
    ax3.set_xticks(range(len(analysis_df)))
    ax3.set_xticklabels(analysis_df['bin'], rotation=45, ha='right')
    ax3.legend()
    ax3.set_yscale('log')
    ax3.grid(axis='y', alpha=0.3)

    # 4. –®–∏—Ä–∏–Ω–∞ –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞
    ax4 = axes[1, 1]
    ax4.bar(range(len(analysis_df)), analysis_df['CI_width'],
            color='steelblue', alpha=0.7)
    ax4.axhline(y=3, color='green', linestyle='--', alpha=0.5, label='–£–∑–∫–∏–π CI (3%)')
    ax4.axhline(y=5, color='orange', linestyle='--', alpha=0.5, label='–ü—Ä–∏–µ–º–ª–µ–º—ã–π CI (5%)')
    ax4.set_xlabel('Bin')
    ax4.set_ylabel('CI Width (%)')
    ax4.set_title('–®–∏—Ä–∏–Ω–∞ –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞')
    ax4.set_xticks(range(len(analysis_df)))
    ax4.set_xticklabels(analysis_df['bin'], rotation=45, ha='right')
    ax4.legend()
    ax4.grid(axis='y', alpha=0.3)

    plt.tight_layout()
    plt.show()


num = 0

if __name__ == '__main__':
    if num == 0:
        compare_with_join()
    elif num == 1:
        df = load_data()
        interval_0 = df[df['target'] == 0]['interval_processed']
        interval_1 = df[df['target'] == 1]['interval_processed']

        print(f"üìä –î–ê–ù–ù–´–ï –î–õ–Ø –ê–ù–ê–õ–ò–ó–ê:")
        print(f"Target=0: {len(interval_0)} –∑–∞–ø–∏—Å–µ–π")
        print(f"Target=1: {len(interval_1)} –∑–∞–ø–∏—Å–µ–π")
        print(f"–û–±—â–∏–π fraud rate: {len(interval_1) / len(df) * 100:.2f}%")

        automatic_binning_analysis(df)
        trend_data = trend_analysis(df)
        outliers = tail_analysis(df)
        r_squared = nonlinear_analysis(df)
        likelihood_ratio, x_range = kde_analysis(df)

        final_report(df, trend_data, r_squared, likelihood_ratio, x_range)

    elif num == 2:
        df = load_data()
        bins = [-2, 0.3, 1.0, 30.1]
        labels = ['–í—ã—Å–æ–∫–æ–∞–∫—Ç–∏–≤–Ω—ã–µ', '–ê–∫—Ç–∏–≤–Ω—ã–µ', '–ú–∞–ª–æ–∞–∫—Ç–∏–≤–Ω—ã–µ']

        result = analyze_manual_bins(
            df=df,
            feature='avg_login_interval_30d',
            target='target',
            bins=bins,
            bin_labels=labels
        )

        visualize_bin_analysis(result, 'avg_login_interval_30d')