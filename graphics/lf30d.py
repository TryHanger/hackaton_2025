import sqlite3
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from sklearn.preprocessing import KBinsDiscretizer
from sklearn.neighbors import KernelDensity
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')


def compare_with_join():
    """
    –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º JOIN.
    –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞: –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è —Å—Ç—Ä–æ–∫–æ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –¥–∞—Ç (–Ω–∞–ø—Ä–∏–º–µ—Ä, '01.—Ñ–µ–≤')
    –≤ —á–∏—Å–ª–æ–≤–æ–π —Ñ–æ—Ä–º–∞—Ç —á–∞—Å—Ç–æ—Ç—ã D.MM (–Ω–∞–ø—Ä–∏–º–µ—Ä, 1.02) –∏ –ø—Ä–∏–≤–µ–¥–µ–Ω–∏–µ –∫ REAL.
    """
    try:
        import sqlite3

        # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –ë–î –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        result_conn = sqlite3.connect(':memory:')
        result_cursor = result_conn.cursor()

        # –ü—Ä–∏—Å–æ–µ–¥–∏–Ω—è–µ–º –æ–±–µ –ë–î
        result_cursor.execute("ATTACH DATABASE '../info_perevody.db' AS info_db")
        result_cursor.execute("ATTACH DATABASE '../perevody.db' AS perevody_db")

        # –°–ª–æ–≤–∞—Ä–∏ –¥–ª—è –∑–∞–º–µ–Ω—ã: '—Ñ–µ–≤' -> '02', '—è–Ω–≤' -> '01'
        month_replacements = {
            '—è–Ω–≤': '01', '—Ñ–µ–≤': '02', '–º–∞—Ä': '03', '–∞–ø—Ä': '04',
            '–º–∞–π': '05', '–∏—é–Ω': '06', '–∏—é–ª': '07', '–∞–≤–≥': '08',
            '—Å–µ–Ω': '09', '–æ–∫—Ç': '10', '–Ω–æ—è': '11', '–¥–µ–∫': '12'
        }

        # SQL-–≤—ã—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ login_frequency_30d
        login_freq_clean_sql = "i.login_frequency_30d"

        # 1. –¶–µ–ø–æ—á–∫–∞ –∑–∞–º–µ–Ω –¥–ª—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ '–º–µ—Å' -> '–ú–ú'
        for ru_abbr, num_month in month_replacements.items():
            # –ó–∞–º–µ–Ω—è–µ–º —Ç–æ—á–∫—É –∏ —Å–æ–∫—Ä–∞—â–µ–Ω–∏–µ –Ω–∞ —Ç–æ—á–∫—É –∏ —á–∏—Å–ª–æ –º–µ—Å—è—Ü–∞: '.—Ñ–µ–≤' -> '.02'
            login_freq_clean_sql = f"REPLACE({login_freq_clean_sql}, '.{ru_abbr}', '.{num_month}')"
            # –¢–∞–∫–∂–µ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å–ª—É—á–∞–π –±–µ–∑ —Ç–æ—á–∫–∏, –µ—Å–ª–∏ '—Ñ–µ–≤' —Å—Ç–æ–∏—Ç —Å—Ä–∞–∑—É –ø–æ—Å–ª–µ —á–∏—Å–ª–∞
            login_freq_clean_sql = f"REPLACE({login_freq_clean_sql}, '{ru_abbr}', '.{num_month}')"

        # 2. –û–∫–æ–Ω—á–∞—Ç–µ–ª—å–Ω–æ–µ –ø—Ä–∏–≤–µ–¥–µ–Ω–∏–µ –∫ REAL (–µ—Å–ª–∏ —Å—Ç—Ä–æ–∫–∞ '1.02' –ø–æ–ª—É—á–µ–Ω–∞)
        # –ï—Å–ª–∏ –∏—Å—Ö–æ–¥–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –±—ã–ª–æ —á–∏—Å–ª–æ–º (–Ω–∞–ø—Ä–∏–º–µ—Ä, 0.666), –æ–Ω–æ –ø—Ä–æ—Ö–æ–¥–∏—Ç –∑–∞–º–µ–Ω—ã –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π.
        login_freq_clean_sql = f"CAST({login_freq_clean_sql} AS REAL)"

        # –°–æ–∑–¥–∞–µ–º —Ç–∞–±–ª–∏—Ü—É —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º NOT NULL, —á—Ç–æ–±—ã –∏—Å–∫–ª—é—á–∏—Ç—å —Å—Ç—Ä–æ–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–∏–≤–µ—Å—Ç–∏ –∫ —á–∏—Å–ª—É
        result_cursor.execute(f"""
            CREATE TABLE login_frequency_30d AS
            SELECT 
                i.cst_dim_id,
                i.transdate,
                {login_freq_clean_sql} AS login_frequency_30d_clean,
                p.target
            FROM info_db.unique_transactions i
            LEFT JOIN perevody_db.unique_transactions p
                ON i.cst_dim_id = p.cst_dim_id 
                AND i.transdate = p.transdate
            WHERE login_frequency_30d_clean IS NOT NULL
        """)

        # --- –¢–µ–ø–µ—Ä—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏ –≤—ã–≤–æ–¥ –∏—Å–ø–æ–ª—å–∑—É—é—Ç –Ω–æ–≤–æ–µ —á–∏—Å—Ç–æ–µ –∏–º—è —Å—Ç–æ–ª–±—Ü–∞ ---

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        result_cursor.execute("SELECT COUNT(*) FROM login_frequency_30d")
        total_count = result_cursor.fetchone()[0]

        result_cursor.execute("SELECT COUNT(*) FROM login_frequency_30d WHERE target IS NOT NULL")
        matched_count = result_cursor.fetchone()[0]

        # NOTE: –¢–µ–ø–µ—Ä—å —Ñ–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –Ω–æ–≤–æ–º—É —á–∏—Å—Ç–æ–º—É —Å—Ç–æ–ª–±—Ü—É!
        result_cursor.execute("SELECT COUNT(*) FROM login_frequency_30d WHERE target = 1")
        target_1_count = result_cursor.fetchone()[0]

        result_cursor.execute("SELECT COUNT(*) FROM login_frequency_30d WHERE target = 0")
        target_0_count = result_cursor.fetchone()[0]

        print("üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –°–†–ê–í–ù–ï–ù–ò–Ø:")
        print(f"–í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π (—á–∏—Å–ª–æ–≤—ã–µ): {total_count}")
        # ... –æ—Å—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ ...
        print(f"–ù–∞–π–¥–µ–Ω–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π: {matched_count}")
        print(f"–ù–µ –Ω–∞–π–¥–µ–Ω–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π: {total_count - matched_count}")
        print(f"Target = 1: {target_1_count}")
        print(f"Target = 0: {target_0_count}")

        # –í—ã–±–æ—Ä–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        result_cursor.execute(
            "SELECT cst_dim_id, transdate, login_frequency_30d_clean, target FROM login_frequency_30d LIMIT 10")
        sample_results = result_cursor.fetchall()

        print("\nüîç –ü–ï–†–í–´–ï 10 –†–ï–ó–£–õ–¨–¢–ê–¢–û–í (–ß–∏—Å–ª–æ–≤–æ–π —Å—Ç–æ–ª–±–µ—Ü –æ—á–∏—â–µ–Ω):")
        print("ID | –î–∞—Ç–∞ | login_frequency_30d_clean | Target")
        print("-" * 50)
        for row in sample_results:
            print(f"{row[0]} | {row[1]} | {row[2]} | {row[3]}")

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ —Ñ–∞–π–ª –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        result_cursor.execute("""
            ATTACH DATABASE '../comparison_results.db' AS results_db
        """)
        result_cursor.execute("""
            CREATE TABLE results_db.login_frequency_30d AS
            SELECT cst_dim_id, transdate, login_frequency_30d_clean AS login_frequency_30d, target 
            FROM login_frequency_30d
        """)

        print("\nüíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ comparison_results.db")

        # –û—Ç—Å–æ–µ–¥–∏–Ω—è–µ–º –ë–î
        result_cursor.execute("DETACH DATABASE info_db")
        result_cursor.execute("DETACH DATABASE perevody_db")
        result_cursor.execute("DETACH DATABASE results_db")

        return total_count

    except sqlite3.Error as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö: {e}")
        return 0
    except NameError:
        print("‚ùå –û—à–∏–±–∫–∞: –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–∞ –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ 'sqlite3'.")
        return 0

def load_data():
    script_dir = Path(__file__).parent
    db_path = script_dir.parent / 'comparison_results.db'
    conn = sqlite3.connect(db_path)
    df = pd.read_sql_query(
        "SELECT login_frequency_30d, target FROM login_frequency_30d WHERE target IS NOT NULL AND login_frequency_30d IS NOT NULL",
        conn
    )
    conn.close()

    print(f"üìä –î–ê–ù–ù–´–ï –î–õ–Ø –ê–ù–ê–õ–ò–ó–ê (login_frequency_30d):")
    print(f"–î–∏–∞–ø–∞–∑–æ–Ω –∑–Ω–∞—á–µ–Ω–∏–π: {df['login_frequency_30d'].min():.2f} - {df['login_frequency_30d'].max():.2f}")
    print(f"Target=0: {len(df[df['target'] == 0])} –∑–∞–ø–∏—Å–µ–π")
    print(f"Target=1: {len(df[df['target'] == 1])} –∑–∞–ø–∏—Å–µ–π")
    print(f"–û–±—â–∏–π fraud rate: {df['target'].mean() * 100:.2f}%")

    return df

def automatic_binning_analysis(df):
    """–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –±–∏–Ω–Ω–∏–Ω–≥ —Å —Ä–∞–∑–Ω—ã–º–∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏—è–º–∏."""

    print("\n" + "=" * 60)
    print("1. –ê–í–¢–û–ú–ê–¢–ò–ß–ï–°–ö–ò–ô –ë–ò–ù–ù–ò–ù–ì")
    print("=" * 60)

    X = df['login_frequency_30d'].values.reshape(-1, 1)

    # –†–∞–∑–Ω—ã–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –±–∏–Ω–Ω–∏–Ω–≥–∞
    strategies = {
        'uniform': '–†–∞–≤–Ω–æ–º–µ—Ä–Ω—ã–π',
        'quantile': '–ö–≤–∞–Ω—Ç–∏–ª—å–Ω—ã–π',
        'kmeans': 'K-—Å—Ä–µ–¥–Ω–∏—Ö'
    }

    fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    axes = axes.ravel()

    for idx, (strategy, name) in enumerate(strategies.items()):
        # –°–æ–∑–¥–∞–µ–º –±–∏–Ω—ã
        discretizer = KBinsDiscretizer(n_bins=8, encode='ordinal', strategy=strategy)
        bins_array = discretizer.fit_transform(X).flatten()

        # –ê–Ω–∞–ª–∏–∑ fraud rate –ø–æ –±–∏–Ω–∞–º
        df_binned = df.copy()
        df_binned['bin'] = bins_array
        bin_stats = df_binned.groupby('bin').agg({
            'login_frequency_30d': ['min', 'max', 'count'],
            'target': ['sum', 'mean']
        }).round(3)

        bin_stats.columns = ['min_login', 'max_login', 'total_count', 'fraud_count', 'fraud_rate']
        bin_stats['fraud_rate_pct'] = (bin_stats['fraud_rate'] * 100).round(2)

        # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
        ax = axes[idx]
        bins_centers = (bin_stats['min_login'] + bin_stats['max_login']) / 2
        ax.plot(bins_centers, bin_stats['fraud_rate_pct'], 'o-', linewidth=2, markersize=8)
        ax.set_title(f'{name} –±–∏–Ω–Ω–∏–Ω–≥\n({strategy})', fontsize=14)
        ax.set_xlabel('–ß–∞—Å—Ç–æ—Ç–∞ –ª–æ–≥–∏–Ω–∞ –∑–∞ 7 –¥–Ω–µ–π', fontsize=12)
        ax.set_ylabel('Fraud Rate (%)', fontsize=12)
        ax.grid(True, alpha=0.3)

        # –î–æ–±–∞–≤–ª—è–µ–º –∑–Ω–∞—á–µ–Ω–∏—è
        for i, (center, rate) in enumerate(zip(bins_centers, bin_stats['fraud_rate_pct'])):
            ax.annotate(f'{rate}%', (center, rate), xytext=(0, 10),
                        textcoords='offset points', ha='center', fontsize=9)

        print(f"\n{name} –±–∏–Ω–Ω–∏–Ω–≥:")
        print(bin_stats[['min_login', 'max_login', 'total_count', 'fraud_rate_pct']])

    # –†—É—á–Ω–æ–π –±–∏–Ω–Ω–∏–Ω–≥ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞
    axes[3].axis('off')
    plt.tight_layout()
    plt.show()

    return df

def trend_analysis(df):
    """–°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ —Ç—Ä–µ–Ω–¥–∞ —Ä–∏—Å–∫–∞ –¥–ª—è login_frequency_30d."""

    print("\n" + "=" * 60)
    print("2. –°–¢–ê–¢–ò–°–¢–ò–ß–ï–°–ö–ò–ô –ê–ù–ê–õ–ò–ó –¢–†–ï–ù–î–ê")
    print("=" * 60)

    # –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –±–∏–Ω—ã –¥–ª—è –¥–∏–∞–ø–∞–∑–æ–Ω–∞ 0-25.7
    bins = [0, 0.1, 0.5, 1, 2, 3, 5, 8, 12, 18, 26]
    labels = ['0', '0.1-0.5', '0.5-1', '1-2', '2-3', '3-5', '5-8', '8-12', '12-18', '18+']

    df['bin'] = pd.cut(df['login_frequency_30d'], bins=bins, labels=labels, right=False)
    trend_data = df.groupby('bin').agg({
        'target': ['count', 'sum', 'mean'],
        'login_frequency_30d': 'median'
    }).round(4)

    trend_data.columns = ['total', 'fraud_count', 'fraud_rate', 'median_freq']
    trend_data['fraud_rate_pct'] = (trend_data['fraud_rate'] * 100).round(2)

    # –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ —Ç–µ—Å—Ç—ã
    X = np.arange(len(trend_data))
    Y = trend_data['fraud_rate'].values

    # –õ–∏–Ω–µ–π–Ω–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è –¥–ª—è —Ç—Ä–µ–Ω–¥–∞
    slope, intercept, r_value, p_value, std_err = stats.linregress(X, Y)

    # –¢–µ—Å—Ç –ú–∞–Ω–Ω–∞-–ö–µ–Ω–¥–∞–ª–ª–∞ (–º–æ–Ω–æ—Ç–æ–Ω–Ω–æ—Å—Ç—å)
    from scipy.stats import kendalltau
    tau, p_tau = kendalltau(X, Y)

    print("üìà –°–¢–ê–¢–ò–°–¢–ò–ö–ê –¢–†–ï–ù–î–ê:")
    print(f"–õ–∏–Ω–µ–π–Ω—ã–π —Ç—Ä–µ–Ω–¥: slope = {slope:.6f}, R¬≤ = {r_value ** 2:.4f}")
    print(f"P-value –ª–∏–Ω–µ–π–Ω–æ—Å—Ç–∏: {p_value:.6f}")
    print(f"–¢–µ—Å—Ç –ö–µ–Ω–¥–∞–ª–ª–∞: tau = {tau:.4f}, p-value = {p_tau:.6f}")
    print(f"–ú–æ–Ω–æ—Ç–æ–Ω–Ω–æ—Å—Ç—å: {'–î–ê' if p_tau < 0.05 and tau > 0 else '–ù–ï–¢'}")

    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ç—Ä–µ–Ω–¥–∞
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))

    # –ì—Ä–∞—Ñ–∏–∫ —Ç—Ä–µ–Ω–¥–∞
    ax1.plot(X, Y * 100, 'o-', linewidth=3, markersize=8, label='–ù–∞–±–ª—é–¥–∞–µ–º—ã–π fraud rate')

    # –õ–∏–Ω–µ–π–Ω—ã–π —Ç—Ä–µ–Ω–¥
    trend_line = intercept + slope * X
    ax1.plot(X, trend_line * 100, '--', color='red', linewidth=2,
             label=f'–õ–∏–Ω–µ–π–Ω—ã–π —Ç—Ä–µ–Ω–¥ (R¬≤={r_value ** 2:.3f})')

    ax1.set_title('–ê–Ω–∞–ª–∏–∑ —Ç—Ä–µ–Ω–¥–∞ Fraud Rate\n(login_frequency_30d)', fontsize=16, fontweight='bold')
    ax1.set_xlabel('–£—Ä–æ–≤–µ–Ω—å –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ (–±–∏–Ω)', fontsize=12)
    ax1.set_ylabel('Fraud Rate (%)', fontsize=12)
    ax1.set_xticks(X)
    ax1.set_xticklabels(labels, rotation=45)
    ax1.legend()
    ax1.grid(True, alpha=0.3)

    # –î–æ–±–∞–≤–ª—è–µ–º –∑–Ω–∞—á–µ–Ω–∏—è
    for i, (x, y) in enumerate(zip(X, Y * 100)):
        ax1.annotate(f'{y:.1f}%', (x, y), xytext=(0, 10),
                     textcoords='offset points', ha='center', fontweight='bold')

    # –î–µ—Ç–∞–ª—å–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞
    ax2.axis('off')
    table_data = []
    for bin_name in labels:
        if bin_name in trend_data.index:
            row = trend_data.loc[bin_name]
            table_data.append([
                bin_name, row['total'], row['fraud_count'],
                f"{row['fraud_rate_pct']}%", f"{row['median_freq']:.2f}"
            ])

    table = ax2.table(cellText=table_data,
                      colLabels=['–ë–∏–Ω', '–í—Å–µ–≥–æ', 'Fraud', 'Fraud%', '–ú–µ–¥–∏–∞–Ω–∞'],
                      loc='center',
                      cellLoc='center')
    table.auto_set_font_size(False)
    table.set_fontsize(10)
    table.scale(1, 1.5)
    ax2.set_title('–î–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –±–∏–Ω–∞–º', fontsize=14, fontweight='bold')

    plt.tight_layout()
    plt.show()

    return trend_data

def tail_analysis(df):
    """–ê–Ω–∞–ª–∏–∑ —Ä–µ–¥–∫–∏—Ö –∑–Ω–∞—á–µ–Ω–∏–π (—Ö–≤–æ—Å—Ç–æ–≤ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è)."""

    print("\n" + "=" * 60)
    print("3. –ê–ù–ê–õ–ò–ó –•–í–û–°–¢–û–í –†–ê–°–ü–†–ï–î–ï–õ–ï–ù–ò–Ø")
    print("=" * 60)

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≤—ã–±—Ä–æ—Å—ã (–±–æ–ª–µ–µ 3 —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã—Ö –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–π)
    mean_logins = df['login_frequency_30d'].mean()
    std_logins = df['login_frequency_30d'].std()
    outlier_threshold = mean_logins + 3 * std_logins

    outliers = df[df['login_frequency_30d'] > outlier_threshold]
    normal_data = df[df['login_frequency_30d'] <= outlier_threshold]

    print(f"–ü–æ—Ä–æ–≥ –≤—ã–±—Ä–æ—Å–æ–≤: > {outlier_threshold:.1f} –ª–æ–≥–∏–Ω–æ–≤")
    print(f"–í—ã–±—Ä–æ—Å–æ–≤: {len(outliers)} –∑–∞–ø–∏—Å–µ–π ({len(outliers) / len(df) * 100:.2f}%)")
    print(f"–í—ã–±—Ä–æ—Å—ã - Fraud Rate: {outliers['target'].mean() * 100:.2f}%")
    print(f"–ù–æ—Ä–º–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è - Fraud Rate: {normal_data['target'].mean() * 100:.2f}%")

    # –ê–Ω–∞–ª–∏–∑ —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
    extreme_thresholds = [50, 100, 150]

    print("\nüîç –ê–ù–ê–õ–ò–ó –≠–ö–°–¢–†–ï–ú–ê–õ–¨–ù–´–• –ó–ù–ê–ß–ï–ù–ò–ô:")
    for threshold in extreme_thresholds:
        extreme_data = df[df['login_frequency_30d'] >= threshold]
        if len(extreme_data) > 0:
            fraud_rate = extreme_data['target'].mean() * 100
            print(f"‚â•{threshold} –ª–æ–≥–∏–Ω–æ–≤: {len(extreme_data)} –∑–∞–ø–∏—Å–µ–π, Fraud Rate: {fraud_rate:.2f}%")

    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ö–≤–æ—Å—Ç–æ–≤
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))

    # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å –≤—ã–¥–µ–ª–µ–Ω–∏–µ–º –≤—ã–±—Ä–æ—Å–æ–≤
    ax1.hist(normal_data['login_frequency_30d'], bins=50, alpha=0.7,
             color='blue', label=f'–ù–æ—Ä–º–∞–ª—å–Ω—ã–µ (‚â§{outlier_threshold:.0f})')
    ax1.hist(outliers['login_frequency_30d'], bins=20, alpha=0.7,
             color='red', label=f'–í—ã–±—Ä–æ—Å—ã (> {outlier_threshold:.0f})')
    ax1.axvline(outlier_threshold, color='black', linestyle='--', linewidth=2, label='–ü–æ—Ä–æ–≥ –≤—ã–±—Ä–æ—Å–æ–≤')
    ax1.set_title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å –≤—ã–¥–µ–ª–µ–Ω–∏–µ–º –≤—ã–±—Ä–æ—Å–æ–≤', fontsize=14)
    ax1.set_xlabel('–ß–∞—Å—Ç–æ—Ç–∞ –ª–æ–≥–∏–Ω–∞ –∑–∞ 7 –¥–Ω–µ–π', fontsize=12)
    ax1.set_ylabel('–ß–∞—Å—Ç–æ—Ç–∞', fontsize=12)
    ax1.legend()
    ax1.grid(True, alpha=0.3)

    # Fraud rate –ø–æ –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª—è–º - –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –ß–ê–°–¢–¨
    percentiles = np.arange(0, 101, 5)
    percentile_values = np.percentile(df['login_frequency_30d'], percentiles)
    percentile_fraud = []

    for p in percentiles:
        threshold = np.percentile(df['login_frequency_30d'], p)
        high_activity = df[df['login_frequency_30d'] >= threshold]
        if len(high_activity) > 0:
            fraud_rate = high_activity['target'].mean() * 100
            percentile_fraud.append(fraud_rate)
        else:
            percentile_fraud.append(0)

    ax2.plot(100 - percentiles, percentile_fraud, 'o-', linewidth=2, markersize=4)
    ax2.set_title('Fraud Rate –ø–æ –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª—è–º –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏\n(—Ç–æ–ø X% —Å–∞–º—ã—Ö –∞–∫—Ç–∏–≤–Ω—ã—Ö)', fontsize=14)
    ax2.set_xlabel('–¢–æ–ø X% —Å–∞–º—ã—Ö –∞–∫—Ç–∏–≤–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π', fontsize=12)
    ax2.set_ylabel('Fraud Rate (%)', fontsize=12)
    ax2.grid(True, alpha=0.3)
    ax2.invert_xaxis()

    # –î–æ–±–∞–≤–ª—è–µ–º –∫–ª—é—á–µ–≤—ã–µ —Ç–æ—á–∫–∏ - –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –ß–ê–°–¢–¨
    key_percentiles = [95, 99, 99.9]
    for p in key_percentiles:
        # –ù–∞—Ö–æ–¥–∏–º –±–ª–∏–∂–∞–π—à–∏–π –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª—å –∏–∑ –Ω–∞—à–µ–≥–æ —Å–ø–∏—Å–∫–∞
        closest_p = min(percentiles, key=lambda x: abs(x - p))
        idx = list(percentiles).index(closest_p)

        # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª—è
        actual_threshold = np.percentile(df['login_frequency_30d'], p)

        ax2.annotate(f'{p}%: {percentile_fraud[idx]:.1f}%\n(‚â•{actual_threshold:.0f} –ª–æ–≥–∏–Ω–æ–≤)',
                     (100 - closest_p, percentile_fraud[idx]),
                     xytext=(10, 5), textcoords='offset points',
                     bbox=dict(boxstyle='round,pad=0.3', facecolor='yellow', alpha=0.7),
                     fontsize=9)

    plt.tight_layout()
    plt.show()

    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å–∞–º—ã—Ö –∞–∫—Ç–∏–≤–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
    print("\nüìä –ê–ù–ê–õ–ò–ó –°–ê–ú–´–• –ê–ö–¢–ò–í–ù–´–• –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–ï–ô:")
    for p in [99, 99.5, 99.9]:
        threshold = np.percentile(df['login_frequency_30d'], p)
        top_users = df[df['login_frequency_30d'] >= threshold]
        if len(top_users) > 0:
            fraud_rate = top_users['target'].mean() * 100
            print(
                f"–¢–æ–ø {100 - p:.1f}% (‚â•{threshold:.0f} –ª–æ–≥–∏–Ω–æ–≤): {len(top_users)} –∑–∞–ø–∏—Å–µ–π, Fraud Rate: {fraud_rate:.2f}%")

    return outliers

def nonlinear_analysis(df):
    """–ü–æ–∏—Å–∫ –Ω–µ–ª–∏–Ω–µ–π–Ω—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π –¥–ª—è login_frequency_30d."""

    print("\n" + "=" * 60)
    print("4. –ü–û–ò–°–ö –ù–ï–õ–ò–ù–ï–ô–ù–´–• –ó–ê–í–ò–°–ò–ú–û–°–¢–ï–ô")
    print("=" * 60)

    # –°–æ–∑–¥–∞–µ–º –∫–æ–ø–∏—é –¥–∞–Ω–Ω—ã—Ö –∏ —Å–æ—Ä—Ç–∏—Ä—É–µ–º
    sorted_df = df.copy().sort_values('login_frequency_30d').reset_index(drop=True)

    # –ê–¥–∞–ø—Ç–∏–≤–Ω–æ–µ –æ–∫–Ω–æ –¥–ª—è —Å–∫–æ–ª—å–∑—è—â–µ–≥–æ —Å—Ä–µ–¥–Ω–µ–≥–æ
    window_size = min(100, len(df) // 10)
    sorted_df['rolling_fraud'] = sorted_df['target'].rolling(window=window_size, center=True).mean()

    # –£–¥–∞–ª—è–µ–º —Å—Ç—Ä–æ–∫–∏ —Å NaN –≤ rolling_fraud
    valid_data = sorted_df.dropna(subset=['rolling_fraud']).copy()

    # –ü–æ–ª–∏–Ω–æ–º–∏–∞–ª—å–Ω–∞—è –∞–ø–ø—Ä–æ–∫—Å–∏–º–∞—Ü–∏—è
    X_poly = valid_data['login_frequency_30d'].values
    Y_poly = valid_data['rolling_fraud'].values

    # –ê–ø–ø—Ä–æ–∫—Å–∏–º–∞—Ü–∏–∏ —Ä–∞–∑–Ω–æ–π —Å—Ç–µ–ø–µ–Ω–∏
    degrees = [1, 2, 3, 4]
    colors = ['red', 'blue', 'green', 'purple']

    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))

    # –ì—Ä–∞—Ñ–∏–∫ 1: –°–∫–æ–ª—å–∑—è—â–µ–µ —Å—Ä–µ–¥–Ω–µ–µ
    ax1.scatter(sorted_df['login_frequency_30d'], sorted_df['target'],
                alpha=0.1, color='gray', s=1, label='–ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ')
    ax1.plot(valid_data['login_frequency_30d'], valid_data['rolling_fraud'] * 100,
             linewidth=3, color='black', label=f'–°–∫–æ–ª—å–∑—è—â–µ–µ —Å—Ä–µ–¥–Ω–µ–µ (n={window_size})')
    ax1.set_title('Fraud Rate vs Login Frequency 7d\n(—Å–∫–æ–ª—å–∑—è—â–µ–µ —Å—Ä–µ–¥–Ω–µ–µ)', fontsize=14)
    ax1.set_xlabel('Login Frequency (7 –¥–Ω–µ–π)', fontsize=12)
    ax1.set_ylabel('Fraud Rate (%)', fontsize=12)

    # –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–π –ø—Ä–µ–¥–µ–ª –¥–ª—è —á–∞—Å—Ç–æ—Ç—ã –ª–æ–≥–∏–Ω–æ–≤
    x_limit = 14
    ax1.set_xlim(0, x_limit)
    ax1.legend()
    ax1.grid(True, alpha=0.3)

    # –ì—Ä–∞—Ñ–∏–∫ 2: –ü–æ–ª–∏–Ω–æ–º–∏–∞–ª—å–Ω–∞—è –∞–ø–ø—Ä–æ–∫—Å–∏–º–∞—Ü–∏—è
    ax2.scatter(X_poly, Y_poly * 100, alpha=0.3, color='gray', s=10, label='–°–≥–ª–∞–∂–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ')

    r_squared = {}
    for degree, color in zip(degrees, colors):
        try:
            coeffs = np.polyfit(X_poly, Y_poly, degree)
            polynomial = np.poly1d(coeffs)
            y_fit = polynomial(X_poly)

            # R¬≤
            ss_res = np.sum((Y_poly - y_fit) ** 2)
            ss_tot = np.sum((Y_poly - np.mean(Y_poly)) ** 2)
            r_sq = 1 - (ss_res / ss_tot) if ss_tot != 0 else 0
            r_squared[degree] = r_sq

            ax2.plot(X_poly, y_fit * 100, color=color, linewidth=2,
                     label=f'–ü–æ–ª–∏–Ω–æ–º {degree} —Å—Ç–µ–ø–µ–Ω–∏ (R¬≤={r_sq:.3f})')
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–ø–ø—Ä–æ–∫—Å–∏–º–∞—Ü–∏–∏ —Å—Ç–µ–ø–µ–Ω–∏ {degree}: {e}")
            r_squared[degree] = 0

    ax2.set_title('–ü–æ–ª–∏–Ω–æ–º–∏–∞–ª—å–Ω–∞—è –∞–ø–ø—Ä–æ–∫—Å–∏–º–∞—Ü–∏—è', fontsize=14)
    ax2.set_xlabel('Login Frequency (7 –¥–Ω–µ–π)', fontsize=12)
    ax2.set_ylabel('Fraud Rate (%)', fontsize=12)
    ax2.set_xlim(0, x_limit)
    ax2.legend()
    ax2.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.show()

    # –ê–Ω–∞–ª–∏–∑ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π —Å—Ç–µ–ø–µ–Ω–∏
    print("üìä –ö–ê–ß–ï–°–¢–í–û –ê–ü–ü–†–û–ö–°–ò–ú–ê–¶–ò–ò:")
    for degree, r_sq in r_squared.items():
        print(f"–ü–æ–ª–∏–Ω–æ–º {degree} —Å—Ç–µ–ø–µ–Ω–∏: R¬≤ = {r_sq:.4f}")

    # –õ–æ–∫–∞–ª—å–Ω—ã–µ –º–∞–∫—Å–∏–º—É–º—ã/–º–∏–Ω–∏–º—É–º—ã –¥–ª—è –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
    if r_squared:
        optimal_degree = max(r_squared, key=r_squared.get)
        try:
            coeffs = np.polyfit(X_poly, Y_poly, optimal_degree)
            polynomial = np.poly1d(coeffs)

            # –ü—Ä–æ–∏–∑–≤–æ–¥–Ω–∞—è –¥–ª—è –ø–æ–∏—Å–∫–∞ —ç–∫—Å—Ç—Ä–µ–º—É–º–æ–≤
            derivative = polynomial.deriv()
            critical_points = derivative.roots

            # –§–∏–ª—å—Ç—Ä—É–µ–º –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–µ —Ç–æ—á–∫–∏ –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ –¥–∞–Ω–Ω—ã—Ö
            real_critical_points = critical_points[np.isreal(critical_points)].real
            real_critical_points = real_critical_points[
                (real_critical_points >= X_poly.min()) &
                (real_critical_points <= X_poly.max())
                ]

            print(f"\nüîç –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ï –¢–û–ß–ö–ò (–ø–æ–ª–∏–Ω–æ–º {optimal_degree} —Å—Ç–µ–ø–µ–Ω–∏):")
            if len(real_critical_points) > 0:
                for point in real_critical_points:
                    fraud_at_point = polynomial(point) * 100
                    point_type = "–ú–ê–ö–°–ò–ú–£–ú" if polynomial.deriv(2)(point) < 0 else "–º–∏–Ω–∏–º—É–º"
                    print(f"  {point:.2f} —á–∞—Å—Ç–æ—Ç—ã: Fraud Rate = {fraud_at_point:.2f}% ({point_type})")
            else:
                print("  –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ —Ç–æ—á–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")

        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö —Ç–æ—á–µ–∫: {e}")

    return r_squared

def kde_analysis(df):
    """Kernel Density Estimation –¥–ª—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π login_frequency_30d."""

    print("\n" + "=" * 60)
    print("5. KERNEL DENSITY ESTIMATION")
    print("=" * 60)

    freq_0 = df[df['target'] == 0]['login_frequency_30d']
    freq_1 = df[df['target'] == 1]['login_frequency_30d']

    # –ê–¥–∞–ø—Ç–∏–≤–Ω–æ–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
    max_val = min(15, df['login_frequency_30d'].max() * 1.1)  # –ù–µ–º–Ω–æ–≥–æ –±–æ–ª—å—à–µ –º–∞–∫—Å–∏–º—É–º–∞
    freq_0_trimmed = freq_0[freq_0 <= max_val]
    freq_1_trimmed = freq_1[freq_1 <= max_val]

    print(f"–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è KDE –¥–ª—è –¥–∏–∞–ø–∞–∑–æ–Ω–∞ 0-{max_val:.1f}")
    print(f"–û—Ö–≤–∞—Ç—ã–≤–∞–µ—Ç {len(freq_0_trimmed) / len(freq_0) * 100:.1f}% –ª–µ–≥–∏—Ç–∏–º–Ω—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π")
    print(f"–û—Ö–≤–∞—Ç—ã–≤–∞–µ—Ç {len(freq_1_trimmed) / len(freq_1) * 100:.1f}% –º–æ—à–µ–Ω–Ω–∏—á–µ—Å–∫–∏—Ö –æ–ø–µ—Ä–∞—Ü–∏–π")

    # KDE —Å —Ä–∞–∑–Ω—ã–º–∏ bandwidth
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))

    bandwidths = [0.1, 0.3, 0.5, 'auto']  # –ú–µ–Ω—å—à–∏–µ bandwidth –¥–ª—è –º–µ–Ω—å—à–µ–≥–æ –¥–∏–∞–ø–∞–∑–æ–Ω–∞
    titles = ['Small bandwidth (0.1)', 'Medium bandwidth (0.3)',
              'Large bandwidth (0.5)', 'Auto bandwidth']

    for idx, (bw, title) in enumerate(zip(bandwidths, titles)):
        ax = axes[idx // 2, idx % 2]

        # KDE –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞
        if bw == 'auto':
            kde_0 = stats.gaussian_kde(freq_0_trimmed)
            kde_1 = stats.gaussian_kde(freq_1_trimmed)
        else:
            kde_0 = stats.gaussian_kde(freq_0_trimmed, bw_method=bw)
            kde_1 = stats.gaussian_kde(freq_1_trimmed, bw_method=bw)

        x_range = np.linspace(0, max_val, 200)

        ax.plot(x_range, kde_0(x_range), label='Target=0 (–õ–µ–≥–∏—Ç–∏–º–Ω—ã–µ)',
                color='blue', linewidth=2)
        ax.plot(x_range, kde_1(x_range), label='Target=1 (–ú–æ—à–µ–Ω–Ω–∏—á–µ—Å–∫–∏–µ)',
                color='red', linewidth=2)

        ax.set_title(f'KDE: {title}', fontsize=14)
        ax.set_xlabel('Login Frequency (7 –¥–Ω–µ–π)', fontsize=12)
        ax.set_ylabel('–ü–ª–æ—Ç–Ω–æ—Å—Ç—å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏', fontsize=12)
        ax.legend()
        ax.grid(True, alpha=0.3)
        ax.set_xlim(0, max_val)

    plt.tight_layout()
    plt.show()

    # Ratio of densities (—Å–∏–≥–Ω–∞–ª –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏)
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))

    # Auto KDE –¥–ª—è ratio –∞–Ω–∞–ª–∏–∑–∞
    kde_0_auto = stats.gaussian_kde(freq_0_trimmed)
    kde_1_auto = stats.gaussian_kde(freq_1_trimmed)

    x_range = np.linspace(0, max_val, 200)
    density_0 = kde_0_auto(x_range)
    density_1 = kde_1_auto(x_range)

    # –û—Ç–Ω–æ—à–µ–Ω–∏–µ –ø–ª–æ—Ç–Ω–æ—Å—Ç–µ–π
    likelihood_ratio = np.where(density_0 > 0, density_1 / density_0, 0)

    ax1.plot(x_range, density_0, label='P(x|Target=0)', color='blue', linewidth=2)
    ax1.plot(x_range, density_1, label='P(x|Target=1)', color='red', linewidth=2)
    ax1.set_title('–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–Ω—ã–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è', fontsize=14)
    ax1.set_xlabel('Login Frequency (7 –¥–Ω–µ–π)', fontsize=12)
    ax1.set_ylabel('–ü–ª–æ—Ç–Ω–æ—Å—Ç—å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏', fontsize=12)
    ax1.legend()
    ax1.grid(True, alpha=0.3)

    ax2.plot(x_range, likelihood_ratio, color='purple', linewidth=3)
    ax2.axhline(y=1, color='black', linestyle='--', alpha=0.5, label='–ü–æ—Ä–æ–≥ (ratio=1)')
    ax2.set_title('Likelihood Ratio: P(x|Target=1) / P(x|Target=0)', fontsize=14)
    ax2.set_xlabel('Login Frequency (7 –¥–Ω–µ–π)', fontsize=12)
    ax2.set_ylabel('Likelihood Ratio', fontsize=12)
    ax2.legend()
    ax2.grid(True, alpha=0.3)

    # –û–±–ª–∞—Å—Ç–∏ –≥–¥–µ –º–æ—à–µ–Ω–Ω–∏–∫–∏ –±–æ–ª–µ–µ –≤–µ—Ä–æ—è—Ç–Ω—ã
    fraud_preferred = x_range[likelihood_ratio > 1]
    if len(fraud_preferred) > 0:
        print(f"üîç –û–ë–õ–ê–°–¢–ò –ü–†–ï–ò–ú–£–©–ï–°–¢–í–ê –ú–û–®–ï–ù–ù–ò–ö–û–í:")
        print(f"  –ß–∞—Å—Ç–æ—Ç–∞ –æ—Ç {fraud_preferred[0]:.2f} –¥–æ {fraud_preferred[-1]:.2f}")

        # –ü–∏–∫ –æ—Ç–Ω–æ—à–µ–Ω–∏—è –ø—Ä–∞–≤–¥–æ–ø–æ–¥–æ–±–∏—è
        peak_idx = np.argmax(likelihood_ratio)
        peak_x = x_range[peak_idx]
        peak_ratio = likelihood_ratio[peak_idx]
        print(f"  –ü–∏–∫ –æ—Ç–Ω–æ—à–µ–Ω–∏—è: {peak_ratio:.2f} –ø—Ä–∏ {peak_x:.2f}")

    plt.tight_layout()
    plt.show()

    return likelihood_ratio, x_range

def final_report(df, trend_data, r_squared, likelihood_ratio, x_range):
    """–§–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç —Å –≤—ã–≤–æ–¥–∞–º–∏ –¥–ª—è login_frequency_30d."""

    print("\n" + "=" * 80)
    print("üéØ –ò–¢–û–ì–û–í–´–ô –û–¢–ß–ï–¢ –ê–ù–ê–õ–ò–ó–ê (login_frequency_30d)")
    print("=" * 80)

    # –ö–ª—é—á–µ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
    total_fraud_rate = df['target'].mean() * 100
    correlation = df['login_frequency_30d'].corr(df['target'])

    print("üìà –ö–õ–Æ–ß–ï–í–´–ï –ú–ï–¢–†–ò–ö–ò:")
    print(f"  ‚Ä¢ –û–±—â–∏–π Fraud Rate: {total_fraud_rate:.2f}%")
    print(f"  ‚Ä¢ –ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è —á–∞—Å—Ç–æ—Ç–∞-—Ä–∏—Å–∫: {correlation:.4f}")
    print(f"  ‚Ä¢ –û–ø—Ç–∏–º–∞–ª—å–Ω–∞—è —Å—Ç–µ–ø–µ–Ω—å –ø–æ–ª–∏–Ω–æ–º–∞: {max(r_squared, key=r_squared.get)}")
    print(f"  ‚Ä¢ –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π likelihood ratio: {np.max(likelihood_ratio):.2f}")

    # –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    print("\nüí° –ü–†–ê–ö–¢–ò–ß–ï–°–ö–ò–ï –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")

    # –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –ø–æ—Ä–æ–≥–∏ –¥–ª—è —á–∞—Å—Ç–æ—Ç—ã
    high_risk_threshold = 8.0
    medium_risk_threshold = 3.0

    high_risk_data = df[df['login_frequency_30d'] >= high_risk_threshold]
    medium_risk_data = df[(df['login_frequency_30d'] >= medium_risk_threshold) &
                          (df['login_frequency_30d'] < high_risk_threshold)]

    print(f"  1. –í–´–°–û–ö–ò–ô –†–ò–°–ö (‚â•{high_risk_threshold} —á–∞—Å—Ç–æ—Ç—ã):")
    print(f"     ‚Ä¢ {len(high_risk_data)} –∑–∞–ø–∏—Å–µ–π ({len(high_risk_data) / len(df) * 100:.1f}%)")
    print(f"     ‚Ä¢ Fraud Rate: {high_risk_data['target'].mean() * 100:.2f}%")

    print(f"  2. –°–†–ï–î–ù–ò–ô –†–ò–°–ö ({medium_risk_threshold}-{high_risk_threshold - 0.1} —á–∞—Å—Ç–æ—Ç—ã):")
    print(f"     ‚Ä¢ {len(medium_risk_data)} –∑–∞–ø–∏—Å–µ–π ({len(medium_risk_data) / len(df) * 100:.1f}%)")
    print(f"     ‚Ä¢ Fraud Rate: {medium_risk_data['target'].mean() * 100:.2f}%")

    # –û–±–ª–∞—Å—Ç–∏ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ —Å–∏–≥–Ω–∞–ª–∞
    peak_signal_idx = np.argmax(likelihood_ratio)
    peak_signal_x = x_range[peak_signal_idx]

    print(f"  3. –ú–ê–ö–°–ò–ú–ê–õ–¨–ù–´–ô –°–ò–ì–ù–ê–õ:")
    print(f"     ‚Ä¢ {peak_signal_x:.2f} —á–∞—Å—Ç–æ—Ç—ã (likelihood ratio = {np.max(likelihood_ratio):.2f})")

    # –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∞—è –∑–Ω–∞—á–∏–º–æ—Å—Ç—å
    from scipy.stats import mannwhitneyu
    freq_0 = df[df['target'] == 0]['login_frequency_30d']
    freq_1 = df[df['target'] == 1]['login_frequency_30d']

    stat, p_value = mannwhitneyu(freq_0, freq_1, alternative='two-sided')

    print(f"\nüìä –°–¢–ê–¢–ò–°–¢–ò–ß–ï–°–ö–ê–Ø –ó–ù–ê–ß–ò–ú–û–°–¢–¨:")
    print(f"  ‚Ä¢ –¢–µ—Å—Ç –ú–∞–Ω–Ω–∞-–£–∏—Ç–Ω–∏: p-value = {p_value:.6f}")
    print(f"  ‚Ä¢ –†–∞–∑–ª–∏—á–∏–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π: {'–ó–ù–ê–ß–ò–ú–û' if p_value < 0.05 else '–ù–ï–ó–ù–ê–ß–ò–ú–û'}")

    # –§–∏–Ω–∞–ª—å–Ω–∞—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
    plt.figure(figsize=(12, 8))

    # –ö–æ–º–ø–æ–∑–∏—Ç–Ω—ã–π –≥—Ä–∞—Ñ–∏–∫
    plt.subplot(2, 1, 1)

    # KDE —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è
    max_kde = min(15, df['login_frequency_30d'].max() * 1.1)
    freq_0_trimmed = freq_0[freq_0 <= max_kde]
    freq_1_trimmed = freq_1[freq_1 <= max_kde]

    kde_0 = stats.gaussian_kde(freq_0_trimmed)
    kde_1 = stats.gaussian_kde(freq_1_trimmed)
    x_kde = np.linspace(0, max_kde, 200)

    plt.plot(x_kde, kde_0(x_kde), label='–õ–µ–≥–∏—Ç–∏–º–Ω—ã–µ (Target=0)', color='blue', linewidth=2)
    plt.plot(x_kde, kde_1(x_kde), label='–ú–æ—à–µ–Ω–Ω–∏—á–µ—Å–∫–∏–µ (Target=1)', color='red', linewidth=2)
    plt.title('–ò—Ç–æ–≥–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑: –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∏ Risk Trend\n(login_frequency_30d)', fontsize=16, fontweight='bold')
    plt.xlabel('Login Frequency (7 –¥–Ω–µ–π)', fontsize=12)
    plt.ylabel('–ü–ª–æ—Ç–Ω–æ—Å—Ç—å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏', fontsize=12)
    plt.legend()
    plt.grid(True, alpha=0.3)

    plt.subplot(2, 1, 2)

    # Fraud rate —Ç—Ä–µ–Ω–¥
    plt.plot(trend_data.index, trend_data['fraud_rate_pct'], 'o-',
             linewidth=3, markersize=8, color='green', label='–ù–∞–±–ª—é–¥–∞–µ–º—ã–π Fraud Rate')
    plt.axhline(y=total_fraud_rate, color='black', linestyle='--',
                label=f'–û–±—â–∏–π Fraud Rate ({total_fraud_rate:.2f}%)')
    plt.title('Fraud Rate –ø–æ —É—Ä–æ–≤–Ω—è–º –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏', fontsize=14)
    plt.xlabel('–£—Ä–æ–≤–µ–Ω—å –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏', fontsize=12)
    plt.ylabel('Fraud Rate (%)', fontsize=12)
    plt.xticks(rotation=45)
    plt.legend()
    plt.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.show()

    print("\n‚úÖ –ê–ù–ê–õ–ò–ó –ó–ê–í–ï–†–®–ï–ù!")

def analyze_manual_bins(df, feature, target, bins, bin_labels=None):
    """
    –í—ã–ø–æ–ª–Ω—è–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ —Ä—É—á–Ω—ã—Ö –±–∏–Ω–æ–≤ –¥–ª—è fraud detection.

    Parameters:
    -----------
    df : pandas.DataFrame
        –ò—Å—Ö–æ–¥–Ω—ã–π –¥–∞—Ç–∞—Ñ—Ä–µ–π–º
    feature : str
        –ù–∞–∑–≤–∞–Ω–∏–µ —á–∏—Å–ª–æ–≤–æ–π –∫–æ–ª–æ–Ω–∫–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä 'login_frequency_30d')
    target : str
        –ö–æ–ª–æ–Ω–∫–∞ —Å —Ç–∞—Ä–≥–µ—Ç–æ–º (0/1)
    bins : list
        –°–ø–∏—Å–æ–∫ –≥—Ä–∞–Ω–∏—Ü –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–≤, –Ω–∞–ø—Ä–∏–º–µ—Ä: [0, 0.5, 1, 2, 3, 5, 8, 100]
    bin_labels : list, optional
        –ù–∞–∑–≤–∞–Ω–∏—è –±–∏–Ω–æ–≤. –ï—Å–ª–∏ None, –≥–µ–Ω–µ—Ä–∏—Ä—É—é—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏

    Returns:
    --------
    pandas.DataFrame
        –¢–∞–±–ª–∏—Ü–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫ –ø–æ –∫–∞–∂–¥–æ–º—É –±–∏–Ω—É —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏
    """

    # –ö–æ–ø–∏—Ä—É–µ–º –¥–∞—Ç–∞—Ñ—Ä–µ–π–º —á—Ç–æ–±—ã –Ω–µ –º–æ–¥–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å –æ—Ä–∏–≥–∏–Ω–∞–ª
    df_work = df.copy()

    # –ë–∞–∑–æ–≤—ã–π fraud rate –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ RRN
    baseline_fraud_rate = df_work[target].mean()

    # –ü—Ä–∏—Å–≤–∞–∏–≤–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏—è–º –±–∏–Ω
    df_work['bin'] = pd.cut(
        df_work[feature],
        bins=bins,
        labels=bin_labels,
        include_lowest=True,
        right=False  # [a, b) - –ø—Ä–∞–≤–∞—è –≥—Ä–∞–Ω–∏—Ü–∞ –Ω–µ –≤–∫–ª—é—á–∞–µ—Ç—Å—è
    )

    # –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ –±–∏–Ω–∞–º
    groups = df_work.groupby('bin', observed=True)

    # –°–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞
    result = []

    for bin_name, group in groups:

        values = group[feature].values

        # –ó–∞—â–∏—Ç–∞ –æ—Ç –ø—É—Å—Ç—ã—Ö –±–∏–Ω–æ–≤
        if len(values) == 0:
            result.append({
                'bin': bin_name,
                'count': 0,
                'fraud_count': 0,
                'fraud_rate': 0,
                'RRN': np.nan,
                'SE': np.nan,
                'CI_lower': np.nan,
                'CI_upper': np.nan,
                'CI_width': np.nan,
                'reliability': 'NO_DATA',
                'mean': np.nan,
                'median': np.nan,
                'std': np.nan,
                'CV%': np.nan,
                'Q25': np.nan,
                'Q75': np.nan,
                'IQR': np.nan,
                'pct_nonzero': np.nan
            })
            continue

        # === –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ï –ú–ï–¢–†–ò–ö–ò –î–õ–Ø FRAUD DETECTION ===

        count = len(values)
        fraud_count = group[target].sum()
        fraud_rate = fraud_count / count if count > 0 else 0

        # üî¥ –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï 1: RRN = –æ—Ç–Ω–æ—à–µ–Ω–∏–µ fraud rates, –∞ –Ω–µ –∫–≤–∞—Ä—Ç–∏–ª–µ–π!
        # RRN (Relative Risk Ratio) - –≤–æ —Å–∫–æ–ª—å–∫–æ —Ä–∞–∑ —Ä–∏—Å–∫ –æ—Ç–ª–∏—á–∞–µ—Ç—Å—è –æ—Ç baseline
        RRN = fraud_rate / baseline_fraud_rate if baseline_fraud_rate > 0 else np.nan

        # üî¥ –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï 2: SE –¥–ª—è –±–∏–Ω–æ–º–∏–∞–ª—å–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è (fraud rate)
        # Standard Error –¥–ª—è –ø—Ä–æ–ø–æ—Ä—Ü–∏–∏
        SE_fraud = np.sqrt(fraud_rate * (1 - fraud_rate) / count) if count > 0 else np.nan

        # 95% Confidence Interval –¥–ª—è fraud rate
        CI_lower = max(0, fraud_rate - 1.96 * SE_fraud) if not np.isnan(SE_fraud) else np.nan
        CI_upper = min(1, fraud_rate + 1.96 * SE_fraud) if not np.isnan(SE_fraud) else np.nan
        CI_width = CI_upper - CI_lower if not np.isnan(CI_lower) else np.nan

        # –û—Ü–µ–Ω–∫–∞ –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏ –±–∏–Ω–∞
        if count >= 500 and CI_width < 0.03:
            reliability = 'HIGH'
        elif count >= 200 and CI_width < 0.05:
            reliability = 'MEDIUM'
        elif count >= 50:
            reliability = 'LOW'
        else:
            reliability = 'VERY_LOW'

        # === –î–ï–°–ö–†–ò–ü–¢–ò–í–ù–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–†–ò–ó–ù–ê–ö–ê ===

        mean = np.mean(values)
        median = np.median(values)
        std = np.std(values, ddof=1) if count > 1 else 0

        # SE –¥–ª—è —Å—Ä–µ–¥–Ω–µ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–∞ (–Ω–µ fraud rate!)
        SE_mean = std / np.sqrt(count) if count > 1 else 0

        # Coefficient of Variation
        CV = (std / mean * 100) if mean != 0 else 0

        Q25 = np.percentile(values, 25)
        Q75 = np.percentile(values, 75)
        IQR = Q75 - Q25  # Interquartile Range

        # –ü—Ä–æ—Ü–µ–Ω—Ç –Ω–µ–Ω—É–ª–µ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
        pct_nonzero = (values != 0).sum() / count * 100 if count > 0 else 0

        result.append({
            # –ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è –±–∏–Ω–∞
            'bin': str(bin_name),

            # === FRAUD –ú–ï–¢–†–ò–ö–ò (–ö–†–ò–¢–ò–ß–ù–û!) ===
            'count': count,
            'fraud_count': int(fraud_count),
            'fraud_rate': round(fraud_rate * 100, 3),  # –≤ –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö
            'RRN': round(RRN, 3),  # ‚úÖ –ü–†–ê–í–ò–õ–¨–ù–´–ô RRN
            'SE': round(SE_fraud * 100, 3),  # ‚úÖ SE –¥–ª—è fraud rate (–≤ –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö)
            'CI_lower': round(CI_lower * 100, 3),  # –≤ –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö
            'CI_upper': round(CI_upper * 100, 3),  # –≤ –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö
            'CI_width': round(CI_width * 100, 3),  # –≤ –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö
            'reliability': reliability,

            # === –î–ï–°–ö–†–ò–ü–¢–ò–í–ù–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê ===
            'mean': round(mean, 3),
            'median': round(median, 3),
            'std': round(std, 3),
            'SE_mean': round(SE_mean, 3),  # SE –¥–ª—è —Å—Ä–µ–¥–Ω–µ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–∞
            'CV%': round(CV, 2),
            'Q25': round(Q25, 3),
            'Q75': round(Q75, 3),
            'IQR': round(IQR, 3),
            'pct_nonzero': round(pct_nonzero, 2)
        })

    result_df = pd.DataFrame(result)

    # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –ø–æ—Ä—è–¥–∫—É –±–∏–Ω–æ–≤ (–µ—Å–ª–∏ bin - –∫–∞—Ç–µ–≥–æ—Ä–∏—è —Å –ø–æ—Ä—è–¥–∫–æ–º)
    if bin_labels is not None:
        result_df['bin'] = pd.Categorical(result_df['bin'], categories=bin_labels, ordered=True)
        result_df = result_df.sort_values('bin')

    return result_df

def visualize_bin_analysis(analysis_df, feature_name):
    """
    –í—ã–≤–æ–¥–∏—Ç –∫—Ä–∞—Å–∏–≤—É—é –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞ –±–∏–Ω–æ–≤
    """
    import matplotlib.pyplot as plt
    import seaborn as sns

    print("=" * 80)
    print(f"üìä –ê–ù–ê–õ–ò–ó –ü–†–ò–ó–ù–ê–ö–ê: {feature_name}")
    print("=" * 80)

    # –û—Å–Ω–æ–≤–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞
    print("\nüéØ FRAUD –ú–ï–¢–†–ò–ö–ò –ü–û –ë–ò–ù–ê–ú:\n")
    display_cols = ['bin', 'count', 'fraud_count', 'fraud_rate', 'RRN',
                    'CI_width', 'reliability']
    print(analysis_df[display_cols].to_string(index=False))

    # –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è –æ –Ω–µ–Ω–∞–¥–µ–∂–Ω—ã—Ö –±–∏–Ω–∞—Ö
    unreliable = analysis_df[analysis_df['reliability'].isin(['LOW', 'VERY_LOW'])]
    if len(unreliable) > 0:
        print("\n‚ö†Ô∏è  –í–ù–ò–ú–ê–ù–ò–ï: –ù–µ–Ω–∞–¥–µ–∂–Ω—ã–µ –±–∏–Ω—ã (—Ç—Ä–µ–±—É—é—Ç –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è):")
        print(unreliable[['bin', 'count', 'fraud_rate', 'CI_width', 'reliability']].to_string(index=False))

    # –í—ã–≤–æ–¥—ã
    print("\n‚úÖ –í–´–í–û–î–´:")

    high_risk = analysis_df[
        (analysis_df['RRN'] >= 1.5) &
        (analysis_df['reliability'].isin(['HIGH', 'MEDIUM']))
        ]
    if len(high_risk) > 0:
        print(f"\nüî¥ –ë–∏–Ω—ã —Å –ü–û–í–´–®–ï–ù–ù–´–ú —Ä–∏—Å–∫–æ–º (RRN ‚â• 1.5, –Ω–∞–¥–µ–∂–Ω—ã–µ):")
        for _, row in high_risk.iterrows():
            print(f"   ‚Ä¢ {row['bin']}: FR={row['fraud_rate']:.2f}%, RRN={row['RRN']:.2f}, n={row['count']}")

    low_risk = analysis_df[
        (analysis_df['RRN'] <= 0.7) &
        (analysis_df['reliability'].isin(['HIGH', 'MEDIUM']))
        ]
    if len(low_risk) > 0:
        print(f"\nüü¢ –ë–∏–Ω—ã —Å –ü–û–ù–ò–ñ–ï–ù–ù–´–ú —Ä–∏—Å–∫–æ–º (RRN ‚â§ 0.7, –Ω–∞–¥–µ–∂–Ω—ã–µ):")
        for _, row in low_risk.iterrows():
            print(f"   ‚Ä¢ {row['bin']}: FR={row['fraud_rate']:.2f}%, RRN={row['RRN']:.2f}, n={row['count']}")

    # –ì—Ä–∞—Ñ–∏–∫
    fig, axes = plt.subplots(2, 2, figsize=(14, 10))

    # 1. Fraud Rate —Å –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–º–∏ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞–º–∏
    ax1 = axes[0, 0]
    reliable = analysis_df[analysis_df['reliability'].isin(['HIGH', 'MEDIUM'])]
    unreliable = analysis_df[~analysis_df['reliability'].isin(['HIGH', 'MEDIUM'])]

    ax1.bar(range(len(reliable)), reliable['fraud_rate'],
            color='steelblue', alpha=0.7, label='–ù–∞–¥–µ–∂–Ω—ã–µ')
    ax1.bar(range(len(reliable), len(analysis_df)), unreliable['fraud_rate'],
            color='lightcoral', alpha=0.5, label='–ù–µ–Ω–∞–¥–µ–∂–Ω—ã–µ')

    # –î–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã
    for i, row in analysis_df.iterrows():
        ax1.errorbar(i, row['fraud_rate'],
                     yerr=row['CI_width'] / 2,
                     fmt='none', color='black', capsize=5, alpha=0.5)

    ax1.set_xlabel('Bin')
    ax1.set_ylabel('Fraud Rate (%)')
    ax1.set_title('Fraud Rate –ø–æ –±–∏–Ω–∞–º —Å 95% CI')
    ax1.set_xticks(range(len(analysis_df)))
    ax1.set_xticklabels(analysis_df['bin'], rotation=45, ha='right')
    ax1.legend()
    ax1.grid(axis='y', alpha=0.3)

    # 2. RRN
    ax2 = axes[0, 1]
    colors = ['green' if r <= 0.7 else 'red' if r >= 1.5 else 'gray'
              for r in analysis_df['RRN']]
    ax2.bar(range(len(analysis_df)), analysis_df['RRN'], color=colors, alpha=0.7)
    ax2.axhline(y=1.0, color='black', linestyle='--', label='Baseline (RRN=1.0)')
    ax2.axhline(y=1.5, color='red', linestyle=':', alpha=0.5, label='High Risk (1.5)')
    ax2.axhline(y=0.7, color='green', linestyle=':', alpha=0.5, label='Low Risk (0.7)')
    ax2.set_xlabel('Bin')
    ax2.set_ylabel('RRN (Relative Risk Ratio)')
    ax2.set_title('–û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π —Ä–∏—Å–∫ –ø–æ –±–∏–Ω–∞–º')
    ax2.set_xticks(range(len(analysis_df)))
    ax2.set_xticklabels(analysis_df['bin'], rotation=45, ha='right')
    ax2.legend()
    ax2.grid(axis='y', alpha=0.3)

    # 3. –†–∞–∑–º–µ—Ä –≤—ã–±–æ—Ä–∫–∏ –∏ –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç—å
    ax3 = axes[1, 0]
    reliability_colors = {
        'HIGH': 'green',
        'MEDIUM': 'orange',
        'LOW': 'red',
        'VERY_LOW': 'darkred',
        'NO_DATA': 'gray'
    }
    colors = [reliability_colors.get(r, 'gray') for r in analysis_df['reliability']]
    ax3.bar(range(len(analysis_df)), analysis_df['count'], color=colors, alpha=0.7)
    ax3.axhline(y=500, color='green', linestyle='--', alpha=0.5, label='High reliability (500)')
    ax3.axhline(y=200, color='orange', linestyle='--', alpha=0.5, label='Medium reliability (200)')
    ax3.set_xlabel('Bin')
    ax3.set_ylabel('Sample Size')
    ax3.set_title('–†–∞–∑–º–µ—Ä –≤—ã–±–æ—Ä–∫–∏ –∏ –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç—å')
    ax3.set_xticks(range(len(analysis_df)))
    ax3.set_xticklabels(analysis_df['bin'], rotation=45, ha='right')
    ax3.legend()
    ax3.set_yscale('log')
    ax3.grid(axis='y', alpha=0.3)

    # 4. –®–∏—Ä–∏–Ω–∞ –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞
    ax4 = axes[1, 1]
    ax4.bar(range(len(analysis_df)), analysis_df['CI_width'],
            color='steelblue', alpha=0.7)
    ax4.axhline(y=3, color='green', linestyle='--', alpha=0.5, label='–£–∑–∫–∏–π CI (3%)')
    ax4.axhline(y=5, color='orange', linestyle='--', alpha=0.5, label='–ü—Ä–∏–µ–º–ª–µ–º—ã–π CI (5%)')
    ax4.set_xlabel('Bin')
    ax4.set_ylabel('CI Width (%)')
    ax4.set_title('–®–∏—Ä–∏–Ω–∞ –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞')
    ax4.set_xticks(range(len(analysis_df)))
    ax4.set_xticklabels(analysis_df['bin'], rotation=45, ha='right')
    ax4.legend()
    ax4.grid(axis='y', alpha=0.3)

    plt.tight_layout()
    plt.show()

num = 2

if __name__ == '__main__':
    if num == 0:
        compare_with_join()
    elif num == 1:
        df = load_data()
        logins_0 = df[df['target'] == 0]['login_frequency_30d']
        logins_1 = df[df['target'] == 1]['login_frequency_30d']

        print(f"üìä –î–ê–ù–ù–´–ï –î–õ–Ø –ê–ù–ê–õ–ò–ó–ê:")
        print(f"Target=0: {len(logins_0)} –∑–∞–ø–∏—Å–µ–π")
        print(f"Target=1: {len(logins_1)} –∑–∞–ø–∏—Å–µ–π")
        print(f"–û–±—â–∏–π fraud rate: {len(logins_1) / len(df) * 100:.2f}%")

        automatic_binning_analysis(df)
        trend_data = trend_analysis(df)
        outliers = tail_analysis(df)
        r_squared = nonlinear_analysis(df)
        likelihood_ratio, x_range = kde_analysis(df)

        final_report(df, trend_data, r_squared, likelihood_ratio, x_range)

        # stats_df = calculate_detailed_stats(df, value_column='login_frequency_30d', target_column='target')
        # formatted_stats = print_detailed_stats(stats_df)

    elif num == 2:
        df = load_data()
        bins = [0, 2.571, 999]
        labels = ["0-2.571", "2.571+"]
        result = analyze_manual_bins(
            df=df,
            feature='login_frequency_30d',
            target='target',
            bins=bins,
            bin_labels=labels
        )

        visualize_bin_analysis(result, 'login_frequency_30d')