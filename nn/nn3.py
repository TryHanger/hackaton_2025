import sqlite3
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split, StratifiedKFold
from catboost import CatBoostClassifier, Pool
from sklearn.metrics import (
    roc_auc_score, classification_report, accuracy_score,
    precision_score, recall_score, f1_score, confusion_matrix
)
from sklearn.impute import SimpleImputer  # <-- –î–æ–±–∞–≤–ª–µ–Ω–æ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ NaN
import warnings

warnings.filterwarnings('ignore')

# –£–î–ê–õ–ï–ù–ê –ò–ó–ë–´–¢–û–ß–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø (–ª–æ–≥–∏–∫–∞ –≤—Å—Ç—Ä–æ–µ–Ω–∞ –Ω–∏–∂–µ)
# def transform_frequency_column(value):
#     ... (—Ñ—É–Ω–∫—Ü–∏—è —É–¥–∞–ª–µ–Ω–∞, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è –∏ —É–ø—Ä–æ—Å—Ç–∏—Ç—å –∫–æ–¥)

# –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö
conn = sqlite3.connect("../clean_data.db")
query = """
SELECT
    cst_dim_id, 
    transdate,
    transdatetime,
    amount,
    monthly_os_changes,
    monthly_phone_model_changes,
    logins_last_7_days,
    logins_last_30_days,
    login_frequency_7d,
    login_frequency_30d,
    freq_change_7d_vs_mean,
    logins_7d_over_30d_ratio,
    avg_login_interval_30d,
    std_login_interval_30d,
    var_login_interval_30d,
    ewm_login_interval_7d,
    burstiness_login_interval,
    fano_factor_login_interval,
    zscore_avg_login_interval_7d,
    target
FROM unique_transactions
"""
df = pd.read_sql_query(query, conn)
conn.close()

print("=== –ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–• ===")
print(f"–ö–æ–ª-–≤–æ –∑–∞–ø–∏—Å–µ–π: {len(df)}")
print(f"–ö–æ–ª-–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(df.columns)}")

target_counts = df['target'].value_counts()
target_percentage = df['target'].value_counts(normalize=True) * 100

print("\n=== –†–ê–°–ü–†–ï–î–ï–õ–ï–ù–ò–ï TARGET ===")
print(f"Class 0 (–ª–µ–≥–∏—Ç–∏–º–Ω—ã–µ): {target_counts[0]} –∑–∞–ø–∏—Å–µ–π ({target_percentage[0]:.2f}%)")
print(f"Class 1 (–º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–æ): {target_counts[1]} –∑–∞–ø–∏—Å–µ–π ({target_percentage[1]:.2f}%)")
print(f"–í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π: {len(df)}")

# =========================================================================================================================== #
#               –ü–û–î–ì–û–¢–û–í–ö–ê –ò –ö–û–ù–°–¢–†–£–ò–†–û–í–ê–ù–ò–ï –ü–†–ò–ó–ù–ê–ö–û–í
# =========================================================================================================================== #
df['transdatetime'] = pd.to_datetime(df['transdatetime'])
df['transdate_day'] = df['transdatetime'].dt.day
df['transdate_dayofweek'] = df['transdatetime'].dt.dayofweek
df['transdate_hour'] = df['transdatetime'].dt.hour
df['transdate_is_business_hours'] = ((df['transdatetime'].dt.hour >= 10) &
                                     (df['transdatetime'].dt.hour <= 18)).astype(int)

df['transdate_year'] = df['transdatetime'].dt.year
df['transdate_month'] = df['transdatetime'].dt.month
df['transdate_minute'] = df['transdatetime'].dt.minute
df['transdate_week'] = df['transdatetime'].dt.isocalendar().week.astype(int)  # –ü—Ä–∏–≤–æ–¥–∏–º –∫ int
df['transdate_quarter'] = df['transdatetime'].dt.quarter

df['amount_log'] = np.log1p(df['amount'])

df['total_device_changes'] = df['monthly_os_changes'] + df['monthly_phone_model_changes']

month_map = {
    '—è–Ω–≤': '01', '—Ñ–µ–≤': '02', '–º–∞—Ä': '03', '–∞–ø—Ä': '04',
    '–º–∞–π': '05', '–∏—é–Ω': '06', '–∏—é–ª': '07', '–∞–≤–≥': '08',
    '—Å–µ–Ω': '09', '–æ–∫—Ç': '10', '–Ω–æ—è': '11', '–¥–µ–∫': '12'
}


# --- –û–ß–ò–°–¢–ö–ê login_frequency_30d ---
# –§—É–Ω–∫—Ü–∏—è transform_frequency_column –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞ –∑–¥–µ—Å—å
def transform_frequency_column(value):
    s = str(value)
    s = s.strip().lower()

    # –°–Ω–∞—á–∞–ª–∞ –ø—ã—Ç–∞–µ–º—Å—è –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å —Ñ–æ—Ä–º–∞—Ç "–¥–µ–Ω—å.–º–µ—Å—è—Ü"
    for text_month, num_month in month_map.items():
        if text_month in s:
            try:
                day_part = s.split('.')[0]
                new_value = f"{day_part}.{num_month}"
                return float(new_value)
            except:
                return np.nan # –ï—Å–ª–∏ —Ñ–æ—Ä–º–∞—Ç –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª

    # –ï—Å–ª–∏ —ç—Ç–æ –Ω–µ –¥–∞—Ç–∞, –æ—á–∏—â–∞–µ–º –¥–µ—Å—è—Ç–∏—á–Ω—ã–π —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å
    s = s.replace(',', '.')

    # –ü—ã—Ç–∞–µ–º—Å—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –æ—Å—Ç–∞–≤—à—É—é—Å—è —Å—Ç—Ä–æ–∫—É –≤ —á–∏—Å–ª–æ.
    # –ï—Å–ª–∏ —ç—Ç–æ —Å—Ç—Ä–æ–∫–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, '01.–º–∞–π' –∏–ª–∏ 'N/A'), –æ–Ω–∞ —Å—Ç–∞–Ω–µ—Ç NaN.
    try:
        return float(s)
    except ValueError:
        return np.nan # –ì–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —á–∏—Å–ª–æ–≤–æ–π NaN

df['login_frequency_30d'] = df['login_frequency_30d'].apply(transform_frequency_column)
df['login_frequency_30d'] = pd.to_numeric(df['login_frequency_30d'], errors='coerce')

df["freq_change_7d_vs_mean"] = (
    df["freq_change_7d_vs_mean"]
    .astype(str)
    .str.strip()
    .str.replace(',', '.') # –ó–∞–º–µ–Ω—è–µ–º –∑–∞–ø—è—Ç—ã–µ –Ω–∞ —Ç–æ—á–∫–∏
)
df["freq_change_7d_vs_mean"] = pd.to_numeric(df["freq_change_7d_vs_mean"], errors='coerce')

# --- –û–ë–†–ê–ë–û–¢–ö–ê –ò–ù–¢–ï–†–í–ê–õ–û–í –ò –°–ï–ù–¢–ò–ù–ï–õ-–ó–ù–ê–ß–ï–ù–ò–ô ---
# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ–π –≥–∏–±—Ä–∏–¥–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ —á–∏—Å–ª–æ–≤—ã—Ö —Å—Ç–æ–ª–±—Ü–æ–≤
def safe_hybrid_transform(df, col):
    # 1. –ü—Ä–∏–≤–µ–¥–µ–Ω–∏–µ –∫ —á–∏—Å–ª—É –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –º—É—Å–æ—Ä–∞ (NaN)
    df[col] = df[col].astype(str).str.strip().str.replace(',', '.')
    df[col] = pd.to_numeric(df[col], errors='coerce')

    # 2. –°–æ–∑–¥–∞–Ω–∏–µ —Ñ–ª–∞–≥–∞ —Å–µ–Ω—Ç–∏–Ω–µ–ª–∞ (-1). –°–Ω–∞—á–∞–ª–∞ –∑–∞–ø–æ–ª–Ω—è–µ–º NaN –Ω—É–ª–µ–º –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ —Ñ–ª–∞–≥–∞
    # *–í–∞–∂–Ω–æ: —ç—Ç–æ –≤—Ä–µ–º–µ–Ω–Ω–æ–µ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ, –¥–ª—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏–º–ø—å—é—Ç–µ—Ä.*
    temp_col = df[col].fillna(0)
    df[f'{col}_is_sentinel'] = (temp_col == -1).astype(int)

    # 3. –õ–æ–≥–∞—Ä–∏—Ñ–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –æ—á–∏—Å—Ç–∫–∞
    df[f'{col}_log'] = np.log1p(temp_col)  # –ü—Ä–∏–º–µ–Ω—è–µ–º log1p –∫ –≤—Ä–µ–º–µ–Ω–Ω–æ–º—É —Å—Ç–æ–ª–±—Ü—É
    df.loc[df[f'{col}_log'] < 0, f'{col}_log'] = 0  # –û—á–∏—â–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –æ—Ç –∑–Ω–∞—á–µ–Ω–∏–π, –≤–æ–∑–Ω–∏–∫—à–∏—Ö –∏–∑ -1

    # 4. –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º NaN –≤ –∏—Å—Ö–æ–¥–Ω—ã—Ö —Å—Ç–æ–ª–±—Ü–∞—Ö, –µ—Å–ª–∏ –æ–Ω–∏ –±—ã–ª–∏ –¥–æ fillna(0)
    # –≠—Ç–æ –≤–∞–∂–Ω–æ, —á—Ç–æ–±—ã SimpleImputer –∑–∞–ø–æ–ª–Ω–∏–ª –∏—Ö –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π –Ω–∞ train set
    df.loc[df[col].isna(), f'{col}_log'] = np.nan
    df.loc[df[col].isna(), f'{col}_is_sentinel'] = np.nan  # *–û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ: –º–æ–∂–Ω–æ –æ—Å—Ç–∞–≤–∏—Ç—å 0, –µ—Å–ª–∏ NaN –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å 0*


# –ü—Ä–∏–º–µ–Ω—è–µ–º –∫ —Å—Ç–æ–ª–±—Ü–∞–º, –≥–¥–µ –æ–∂–∏–¥–∞–µ—Ç—Å—è -1 –∏–ª–∏ —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç:
safe_hybrid_transform(df, 'avg_login_interval_30d')
safe_hybrid_transform(df, 'std_login_interval_30d')
safe_hybrid_transform(df, 'var_login_interval_30d')
safe_hybrid_transform(df, 'ewm_login_interval_7d')
safe_hybrid_transform(df, 'fano_factor_login_interval')

# ‚ö†Ô∏è –£–î–ê–õ–Ø–ï–ú —Å—Ç–∞—Ä—ã–µ, –Ω–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã
df = df.drop(columns=['avg_login_interval_30d', 'std_login_interval_30d', 'var_login_interval_30d',
                      'ewm_login_interval_7d', 'fano_factor_login_interval', 'amount',
                      'cst_dim_id', 'transdate', 'transdatetime'])

print("=== –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê –í–°–ï–• –°–¢–û–õ–ë–¶–û–í ===")

for col in df.columns:
    dtype = df[col].dtype
    if dtype == 'object':
        # –ü–æ–∫–∞–∂–µ–º –ø—Ä–∏–º–µ—Ä—ã —Å—Ç—Ä–æ–∫–æ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
        sample_values = df[col].dropna().head(3).tolist()
        print(f"–°—Ç–æ–ª–±–µ—Ü {col} (object): –ø—Ä–∏–º–µ—Ä—ã {sample_values}")

        # –ü—Ä–æ–≤–µ—Ä–∏–º, —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ —Ä—É—Å—Å–∫–∏–µ –º–µ—Å—è—Ü—ã
        has_russian_months = any(any(month in str(val).lower() for month in month_map.keys())
                                 for val in df[col].dropna().head(10))
        if has_russian_months:
            print(f"  ‚ö†Ô∏è  –°–æ–¥–µ—Ä–∂–∏—Ç —Ä—É—Å—Å–∫–∏–µ –º–µ—Å—è—Ü—ã!")

    elif np.issubdtype(dtype, np.number):
        # –î–ª—è —á–∏—Å–ª–æ–≤—ã—Ö —Å—Ç–æ–ª–±—Ü–æ–≤ –ø—Ä–æ–≤–µ—Ä–∏–º –Ω–∞ –≤—ã–±—Ä–æ—Å—ã
        if df[col].notna().sum() > 0:
            print(f"–°—Ç–æ–ª–±–µ—Ü {col} ({dtype}): min={df[col].min():.2f}, max={df[col].max():.2f}")

# =========================================================================================================================== #
#                   –û–ü–†–ï–î–ï–õ–ï–ù–ò–ï –ü–†–ò–ó–ù–ê–ö–û–í –ò –û–ë–£–ß–ï–ù–ò–ï
# =========================================================================================================================== #

features_final = [
    # –í—Ä–µ–º–µ–Ω–Ω—ã–µ
    "transdate_day", "transdate_dayofweek", "transdate_hour",
    "transdate_is_business_hours", "transdate_year", "transdate_month",
    "transdate_minute", "transdate_week", "transdate_quarter",

    # –°—É–º–º–∞ –∏ –ò–∑–º–µ–Ω–µ–Ω–∏—è –£—Å—Ç—Ä–æ–π—Å—Ç–≤
    "amount_log", "total_device_changes", "monthly_os_changes", "monthly_phone_model_changes",

    # –ò—Å—Ö–æ–¥–Ω—ã–µ –ü–æ–≤–µ–¥–µ–Ω—á–µ—Å–∫–∏–µ (—Ç–æ–∂–µ –º–æ–≥—É—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å NaN –ø–æ—Å–ª–µ to_numeric)
    "logins_last_7_days", "logins_last_30_days", "login_frequency_7d",
    "login_frequency_30d", "freq_change_7d_vs_mean", "logins_7d_over_30d_ratio",
    "burstiness_login_interval", "zscore_avg_login_interval_7d",

    # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–Ω—ã–µ –ò–Ω—Ç–µ—Ä–≤–∞–ª—ã
    "avg_login_interval_30d_log", "std_login_interval_30d_log",
    "var_login_interval_30d_log", "ewm_login_interval_7d_log",
    "fano_factor_login_interval_log",

    # –§–ª–∞–≥–∏ –ú–∞—Ä–∫–µ—Ä–æ–≤ (-1)
    "avg_login_interval_30d_is_sentinel", "std_login_interval_30d_is_sentinel",
    "var_login_interval_30d_is_sentinel", "ewm_login_interval_7d_is_sentinel",
    "fano_factor_login_interval_is_sentinel"
]

CATEGORICAL_FEATURES = [
    # –í—Ä–µ–º–µ–Ω–Ω—ã–µ (—Ü–∏–∫–ª–∏—á–Ω—ã–µ/–¥–∏—Å–∫—Ä–µ—Ç–Ω—ã–µ)
    "transdate_dayofweek",
    "transdate_hour",
    "transdate_week",
    "transdate_day",
    "transdate_month",
    "transdate_quarter",

    # –°—á–µ—Ç—á–∏–∫–∏ (–¥–∏—Å–∫—Ä–µ—Ç–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è 0-N)
    "monthly_os_changes",
    "monthly_phone_model_changes",
    "total_device_changes"
]

X = df[features_final]
y = df['target']

# 1. –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.2,
    random_state=42,
    stratify=y
)

# 2. –û–±—Ä–∞–±–æ—Ç–∫–∞ NaN —Å –ø–æ–º–æ—â—å—é SimpleImputer (–º–µ–¥–∏–∞–Ω–∞)
imputer = SimpleImputer(strategy='median')
# –û–±—É—á–∞–µ–º –∏–º–ø—å—é—Ç–µ—Ä —Ç–æ–ª—å–∫–æ –Ω–∞ –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–µ
X_train_imputed = imputer.fit_transform(X_train)
X_test_imputed = imputer.transform(X_test)

# –í–æ–∑–≤—Ä–∞—â–∞–µ–º –≤ DataFrame –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –∏–º–µ–Ω–∞–º–∏ —Å—Ç–æ–ª–±—Ü–æ–≤ –∏ —Ç–∏–ø–∞–º–∏ –¥–∞–Ω–Ω—ã—Ö
X_train_final = pd.DataFrame(X_train_imputed, columns=features_final)
X_test_final = pd.DataFrame(X_test_imputed, columns=features_final)

# 3. üõë –ö–†–ò–¢–ò–ß–ï–°–ö–û–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ü–†–ò–í–ï–î–ï–ù–ò–ï –ö–ê–¢–ï–ì–û–†–ò–ê–õ–¨–ù–´–• –¢–ò–ü–û–í
# Imputer –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç float, CatBoost —Ç—Ä–µ–±—É–µ—Ç int/str –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–π.
for col in CATEGORICAL_FEATURES:
    # –û–∫—Ä—É–≥–ª—è–µ–º –¥–æ –±–ª–∏–∂–∞–π—à–µ–≥–æ —Ü–µ–ª–æ–≥–æ –∏ –ø—Ä–∏–≤–æ–¥–∏–º –∫ —Ç–∏–ø—É 'int'
    X_train_final[col] = X_train_final[col].round(0).astype(int)
    X_test_final[col] = X_test_final[col].round(0).astype(int)

# 4. –û–±—É—á–µ–Ω–∏–µ CatBoost
print("\n=== –ù–ê–ß–ê–õ–û –û–ë–£–ß–ï–ù–ò–Ø CATBOOST ===")
model_w = CatBoostClassifier(
    iterations=1500,
    learning_rate=0.03,
    depth=8,
    loss_function='Logloss',
    eval_metric='AUC',
    auto_class_weights='Balanced',
    verbose=200,
    random_seed=42,
    cat_features=CATEGORICAL_FEATURES,
)

model_w.fit(
    X_train_final,
    y_train,
    eval_set=(X_test_final, y_test)
)

preds = model_w.predict(X_test_final)
probs = model_w.predict_proba(X_test_final)[:, 1]

print("\n=== –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ú–û–î–ï–õ–ò ===")
print(f"AUC: {roc_auc_score(y_test, probs):.4f}")
print(classification_report(y_test, preds))