import sqlite3
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split, StratifiedKFold
from catboost import CatBoostClassifier, Pool
from sklearn.metrics import (
    roc_auc_score, classification_report, accuracy_score,
    precision_score, recall_score, f1_score, confusion_matrix
)
import warnings
warnings.filterwarnings('ignore')

conn = sqlite3.connect("../clean_data.db")
query = """
SELECT
    cst_dim_id, 
    transdate,
    transdatetime,
    amount,
    monthly_os_changes,
    monthly_phone_model_changes,
    logins_last_7_days,
    logins_last_30_days,
    login_frequency_7d,
    login_frequency_30d,
    freq_change_7d_vs_mean,
    logins_7d_over_30d_ratio,
    avg_login_interval_30d,
    std_login_interval_30d,
    var_login_interval_30d,
    ewm_login_interval_7d,
    burstiness_login_interval,
    fano_factor_login_interval,
    zscore_avg_login_interval_7d,
    target
FROM unique_transactions
"""
df= pd.read_sql_query(query, conn)
conn.close()

print("=== –ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–• ===")
print(f"–ö–æ–ª-–≤–æ –∑–∞–ø–∏—Å–µ–π: {len(df)}")
print(f"–ö–æ–ª-–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(df.columns)}")
print("–°—Ç–æ–ª–±—Ü—ã:", list(df.columns))

target_counts = df['target'].value_counts()
target_percentage = df['target'].value_counts(normalize=True) * 100

print("\n=== –†–ê–°–ü–†–ï–î–ï–õ–ï–ù–ò–ï TARGET ===")
print(f"Class 0 (–ª–µ–≥–∏—Ç–∏–º–Ω—ã–µ): {target_counts[0]} –∑–∞–ø–∏—Å–µ–π ({target_percentage[0]:.2f}%)")
print(f"Class 1 (–º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–æ): {target_counts[1]} –∑–∞–ø–∏—Å–µ–π ({target_percentage[1]:.2f}%)")
print(f"–í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π: {len(df)}")


def transform_frequency_column(value):
    """
    –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —Å—Ç—Ä–æ–∫—É, —Å–æ–¥–µ—Ä–∂–∞—â—É—é –¥–∞—Ç—É (–Ω–∞–ø—Ä–∏–º–µ—Ä, '01.–º–∞—Ä'), –≤ —á–∏—Å–ª–æ–≤–æ–π —Ñ–æ—Ä–º–∞—Ç (–Ω–∞–ø—Ä–∏–º–µ—Ä, 1.03).
    –ö–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ —á–∏—Å–ª–æ–≤—ã–µ —Å—Ç—Ä–æ–∫–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, '0.9333...') –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π.
    """
    s = str(value)
    s = s.strip().lower()  # –£–¥–∞–ª—è–µ–º –ø—Ä–æ–±–µ–ª—ã –∏ –ø—Ä–∏–≤–æ–¥–∏–º –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏

    # –ü—Ä–æ–≤–µ—Ä–∫–∞, —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ —Å—Ç—Ä–æ–∫–∞ –º–µ—Å—è—Ü—ã
    for text_month, num_month in month_map.items():
        if text_month in s:
            try:
                # 01.–º–∞—Ä -> 01.03 (–î–µ–Ω—å.–ú–µ—Å—è—Ü)
                day_part = s.split('.')[0]

                # –°–æ–µ–¥–∏–Ω—è–µ–º '–¥–µ–Ω—å' –∏ '–Ω–æ–º–µ—Ä –º–µ—Å—è—Ü–∞' —á–µ—Ä–µ–∑ —Ç–æ—á–∫—É
                new_value = f"{day_part}.{num_month}"

                # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —á–∏—Å–ª–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
                return float(new_value)
            except:
                # –ï—Å–ª–∏ —á—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º NaN
                return np.nan

                # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã—Ö —á–∏—Å–ª–æ–≤—ã—Ö —Å—Ç—Ä–æ–∫ (—Å –∑–∞–ø—è—Ç–æ–π –∏–ª–∏ —Ç–æ—á–∫–æ–π)
    s = s.replace(',', '.')

    # –ü–æ–ø—ã—Ç–∫–∞ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –æ—á–∏—â–µ–Ω–Ω—É—é —Å—Ç—Ä–æ–∫—É –≤ —á–∏—Å–ª–æ
    try:
        return float(s)
    except ValueError:
        return np.nan

# =========================================================================================================================== #
#               –ü–û–î–ì–û–¢–û–í–ö–ê –î–ê–ù–ù–´–•
# =========================================================================================================================== #
df['transdatetime'] = pd.to_datetime(df['transdatetime'])
df['transdate_day'] = df['transdatetime'].dt.day
df['transdate_dayofweek'] = df['transdatetime'].dt.dayofweek
df['transdate_hour'] = df['transdatetime'].dt.hour
df['transdate_is_business_hours'] = ((df['transdatetime'].dt.hour >= 10) &
                                     (df['transdatetime'].dt.hour <= 18)).astype(int)

df['transdate_year'] = df['transdatetime'].dt.year
df['transdate_month'] = df['transdatetime'].dt.month
df['transdate_minute'] = df['transdatetime'].dt.minute
df['transdate_week'] = df['transdatetime'].dt.isocalendar().week
df['transdate_quarter'] = df['transdatetime'].dt.quarter

df['amount_log'] = np.log1p(df['amount'])

df['total_device_changes'] = df['monthly_os_changes'] + df['monthly_phone_model_changes']

month_map = {
    '—è–Ω–≤': '01', '—Ñ–µ–≤': '02', '–º–∞—Ä': '03', '–∞–ø—Ä': '04',
    '–º–∞–π': '05', '–∏—é–Ω': '06', '–∏—é–ª': '07', '–∞–≤–≥': '08',
    '—Å–µ–Ω': '09', '–æ–∫—Ç': '10', '–Ω–æ—è': '11', '–¥–µ–∫': '12'
}
df['login_frequency_30d'] = df['login_frequency_30d'].apply(transform_frequency_column)

df["freq_change_7d_vs_mean"] = (
    df["freq_change_7d_vs_mean"]
    .astype(str)
    .str.strip()
    .str.replace(',', '.') # –ó–∞–º–µ–Ω—è–µ–º –∑–∞–ø—è—Ç—ã–µ –Ω–∞ —Ç–æ—á–∫–∏
)
df["freq_change_7d_vs_mean"] = pd.to_numeric(df["freq_change_7d_vs_mean"], errors='coerce')

df['avg_30d_is_sentinel'] = (df['avg_login_interval_30d'] == -1).astype(int)
df['avg_login_interval_30d_log'] = np.log1p(df['avg_login_interval_30d'])
df.loc[df['avg_login_interval_30d_log'] < 0, 'avg_login_interval_30d_log'] = 0

df['std_30d_is_sentinel'] = (df['std_login_interval_30d'] == -1).astype(int)
df['std_login_interval_30d_log'] = np.log1p(df['std_login_interval_30d'])
df.loc[df['std_login_interval_30d_log'] < 0, 'std_login_interval_30d_log'] = 0

df['var_login_interval_30d'] = (
    df['var_login_interval_30d']
    .astype(str)
    .str.strip()
    .str.replace(',', '.')
)
df['var_login_interval_30d'] = pd.to_numeric(
    df['var_login_interval_30d'],
    errors='coerce'
)
df['var_30d_is_sentinel'] = (df['var_login_interval_30d'] == -1).astype(int)
df['var_login_interval_30d_log'] = np.log1p(df['var_login_interval_30d'])
df.loc[df['var_login_interval_30d_log'] < 0, 'var_login_interval_30d_log'] = 0

df['ewm_7d_is_sentinel'] = (df['ewm_login_interval_7d'] == -1).astype(int)
df['ewm_login_interval_7d_log'] = np.log1p(df['ewm_login_interval_7d'])
df.loc[df['ewm_login_interval_7d_log'] < 0, 'ewm_login_interval_7d_log'] = 0

df['fano_factor_is_sentinel'] = (df['fano_factor_login_interval'] == -1).astype(int)
df['fano_factor_login_interval_log'] = np.log1p(df['fano_factor_login_interval'])
df.loc[df['fano_factor_login_interval_log'] < 0, 'fano_factor_login_interval_log'] = 0



df['amount_x_hour'] = df['amount_log'] * df['transdate_hour']
df['amount_x_is_business'] = df['amount_log'] * df['transdate_is_business_hours']
df['amount_x_weekend'] = df['amount_log'] * (df['transdate_dayofweek'] >= 5).astype(int)

# –°–µ–∑–æ–Ω–Ω–æ—Å—Ç—å –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
df['zscore_x_hour'] = df['zscore_avg_login_interval_7d'] * df['transdate_hour']
df['zscore_x_day'] = df['zscore_avg_login_interval_7d'] * df['transdate_day']
# =========================================================================================================================== #
# =========================================================================================================================== #

features_final = [
    # –í—Ä–µ–º–µ–Ω–Ω—ã–µ
    "transdate_day",
    # "transdate_dayofweek",
    "transdate_hour",
    # "transdate_is_business_hours",
    # "transdate_year",
    "transdate_month",
    "transdate_minute",
    "transdate_week",
    # "transdate_quarter",

    # –°—É–º–º–∞ –∏ –ò–∑–º–µ–Ω–µ–Ω–∏—è –£—Å—Ç—Ä–æ–π—Å—Ç–≤
    "amount_log",
    # "total_device_changes",
    # "monthly_os_changes",
    # "monthly_phone_model_changes",

    # –ò—Å—Ö–æ–¥–Ω—ã–µ –ü–æ–≤–µ–¥–µ–Ω—á–µ—Å–∫–∏–µ (—Ç–æ–∂–µ –º–æ–≥—É—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å NaN –ø–æ—Å–ª–µ to_numeric)
    "logins_last_7_days",
    "logins_last_30_days",
    # "login_frequency_7d",
    # "login_frequency_30d",
    "freq_change_7d_vs_mean",
    # "logins_7d_over_30d_ratio",
    "burstiness_login_interval",
    "zscore_avg_login_interval_7d",

    # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–Ω—ã–µ –ò–Ω—Ç–µ—Ä–≤–∞–ª—ã
    "avg_login_interval_30d_log",
    # "std_login_interval_30d_log",
    # "var_login_interval_30d_log",
    "ewm_login_interval_7d_log",
    "fano_factor_login_interval_log",

    # –§–ª–∞–≥–∏ –ú–∞—Ä–∫–µ—Ä–æ–≤ (-1)
    # "avg_30d_is_sentinel", "std_30d_is_sentinel",
    # "var_30d_is_sentinel", "ewm_7d_is_sentinel",
    # "fano_factor_is_sentinel"
    
    'amount_x_hour',
    'amount_x_is_business',
    'amount_x_weekend',
    'zscore_x_hour',
    'zscore_x_day',
]

CATEGORICAL_FEATURES = [
    # –í—Ä–µ–º–µ–Ω–Ω—ã–µ (—Ü–∏–∫–ª–∏—á–Ω—ã–µ/–¥–∏—Å–∫—Ä–µ—Ç–Ω—ã–µ)
    # "transdate_dayofweek",
    "transdate_hour",
    "transdate_week",
    "transdate_day",
    "transdate_month",
    # "transdate_quarter",

    # –°—á–µ—Ç—á–∏–∫–∏ (–¥–∏—Å–∫—Ä–µ—Ç–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è 0-N)
    # "monthly_os_changes",
    # "monthly_phone_model_changes",
    # "total_device_changes"
]

# =========================================================================================================================== #
# =========================================================================================================================== #

X = df[features_final]
y = df['target']

from sklearn.model_selection import train_test_split
# from imblearn.over_sampling import SMOTE
#
# smote = SMOTE(
#     sampling_strategy='auto',  # –°—Ç—Ä–∞—Ç–µ–≥–∏—è –≤—ã–±–æ—Ä–∫–∏. 'auto' –æ–∑–Ω–∞—á–∞–µ—Ç —É–≤–µ–ª–∏—á–µ–Ω–∏–µ –º–µ–Ω—å—à–µ–≥–æ –∫–ª–∞—Å—Å–∞ –¥–æ —Ä–∞–∑–º–µ—Ä–∞ –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ.
#     random_state=None,         # –ó–µ—Ä–Ω–æ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ —Å–ª—É—á–∞–π–Ω—ã—Ö —á–∏—Å–µ–ª.
#     k_neighbors=5,             # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–ª–∏–∂–∞–π—à–∏—Ö —Å–æ—Å–µ–¥–µ–π –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–∏–º–µ—Ä–æ–≤.
#     n_jobs=1                   # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —è–¥–µ—Ä –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π —Ä–∞–±–æ—Ç—ã. -1 –æ–∑–Ω–∞—á–∞–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≤—Å–µ—Ö –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —è–¥–µ—Ä.
# )

# –ü—Ä–µ–¥–ø–æ–ª–æ–∂–∏–º, —á—Ç–æ X ‚Äî –≤—Å–µ –ø—Ä–∏–∑–Ω–∞–∫–∏, y ‚Äî –±–∏–Ω–∞—Ä–Ω–∞—è —Ü–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è (0/1)
X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.2,
    random_state=42,
    stratify=y
)

# X_resampled, y_resampled = smote.fit_resample(X_train, y_train)

# =========================================================================================================================== #
# üõë –ù–û–í–´–ô –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô –ë–õ–û–ö: –ò–ú–ü–¨–Æ–¢–ê–¶–ò–Ø (–ú–ï–î–ò–ê–ù–ê) –ò –ü–†–ò–í–ï–î–ï–ù–ò–ï –¢–ò–ü–û–í
# =========================================================================================================================== #
from sklearn.impute import SimpleImputer

print("\n=== –û–ë–†–ê–ë–û–¢–ö–ê NaN –ò –ü–†–ò–í–ï–î–ï–ù–ò–ï –¢–ò–ü–û–í ===")
# 1. –ò–º–ø—å—é—Ç–∞—Ü–∏—è NaN —Å –ø–æ–º–æ—â—å—é SimpleImputer (–º–µ–¥–∏–∞–Ω–∞)
imputer = SimpleImputer(strategy='median')

# –û–±—É—á–∞–µ–º –∏–º–ø—å—é—Ç–µ—Ä —Ç–æ–ª—å–∫–æ –Ω–∞ –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–µ –∏ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∏—Ä—É–µ–º –æ–±–µ
X_train_imputed = imputer.fit_transform(X_train)
X_test_imputed = imputer.transform(X_test)

# –í–æ–∑–≤—Ä–∞—â–∞–µ–º –≤ DataFrame –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∏–º–µ–Ω —Å—Ç–æ–ª–±—Ü–æ–≤
X_train_final = pd.DataFrame(X_train_imputed, columns=features_final)
X_test_final = pd.DataFrame(X_test_imputed, columns=features_final)


# 2. –ü—Ä–∏–≤–µ–¥–µ–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö —Ç–∏–ø–æ–≤ –∫ INT
# –í—Å–µ —Å—Ç–æ–ª–±—Ü—ã –ø–æ—Å–ª–µ –∏–º–ø—å—é—Ç–µ—Ä–∞ - float. CatBoost —Ç—Ä–µ–±—É–µ—Ç int/str –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–π.
for col in CATEGORICAL_FEATURES:
    # –û–∫—Ä—É–≥–ª—è–µ–º –¥–æ –±–ª–∏–∂–∞–π—à–µ–≥–æ —Ü–µ–ª–æ–≥–æ (—á—Ç–æ–±—ã 4.0 —Å—Ç–∞–ª–æ 4) –∏ –ø—Ä–∏–≤–æ–¥–∏–º –∫ —Ç–∏–ø—É 'int'
    X_train_final[col] = X_train_final[col].round(0).astype(int)
    X_test_final[col] = X_test_final[col].round(0).astype(int)

print("–¢–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö —É—Å–ø–µ—à–Ω–æ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω—ã.")
print(X_train_final[CATEGORICAL_FEATURES].dtypes)
# =========================================================================================================================== #

from catboost import CatBoostClassifier
from sklearn.metrics import classification_report, roc_auc_score

model_w = CatBoostClassifier(
    iterations=3000,
    learning_rate=0.03,
    depth=8,
    loss_function='Logloss',
    eval_metric='AUC',
    # class_weights=[1, 67],
    # class_weights=[1, 85],
    class_weights=[1, 100],
    # auto_class_weights='Balanced', #'SqrtBalanced' - —Ç–æ–∂–µ –º–æ–∂–Ω–æ –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å, –Ω–æ –±–∞–∑–∞ 'Balanced'
    verbose=200,
    cat_features=CATEGORICAL_FEATURES,
    # task_type='CPU',
    # thread_count=-1,
)

model_w.fit(X_train_final, y_train, early_stopping_rounds=100)

preds = model_w.predict(X_test_final)
probs = model_w.predict_proba(X_test_final)[:, 1]

results = pd.DataFrame({
    'Actual_Target': y_test.reset_index(drop=True),
    'Prob_Fraud': probs
})

# –°–º–æ—Ç—Ä–∏–º –Ω–∞ 5 —Å–ª—É—á–∞–µ–≤ —Å —Å–∞–º–æ–π –≤—ã—Å–æ–∫–æ–π –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–æ–π –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é –º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–∞
print("\n=== –¢–û–ü-5 –ü–†–û–ì–ù–û–ó–û–í –ú–û–®–ï–ù–ù–ò–ß–ï–°–¢–í–ê ===")
print(results.sort_values(by='Prob_Fraud', ascending=False))

# =========================================================================================================================== #
#                   –ò–©–ï–ú –ü–û–†–û–ì –í–•–û–î–ê –î–õ–Ø –ú–û–®–ï–ù–ù–ò–ß–ï–°–ö–û–ô –¢–†–ê–ù–ó–ê–ö–¶–ò–ò
# =========================================================================================================================== #

# –ù–∞—Ö–æ–¥–∏–º –ª—É—á—à–∏–π –ø–æ—Ä–æ–≥ –¥–ª—è –º–∞–∫—Å–∏–º–∏–∑–∞—Ü–∏–∏ F1-score (–æ–±—â–µ–≥–æ –±–∞–ª–∞–Ω—Å–∞)
best_f1 = 0
best_thresh = 0.5

# –ü–µ—Ä–µ–±–∏—Ä–∞–µ–º –ø–æ—Ä–æ–≥–∏ –æ—Ç 0.005 –¥–æ 0.3 —Å —à–∞–≥–æ–º 0.005
# –ú—ã –Ω–∞—á–∞–ª–∏ —Å –æ—á–µ–Ω—å –Ω–∏–∑–∫–æ–≥–æ –ø–æ—Ä–æ–≥–∞, —á—Ç–æ–±—ã —É—á–µ—Å—Ç—å –Ω–∏–∑–∫–∏–µ Prob_Fraud
for thresh in np.arange(0.005, 0.3, 0.005):
    # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π –≤ –∫–ª–∞—Å—Å—ã —Å –Ω–æ–≤—ã–º –ø–æ—Ä–æ–≥–æ–º
    current_preds = (probs > thresh).astype(int)

    # –ó–∞—â–∏—Ç–∞ –æ—Ç –¥–µ–ª–µ–Ω–∏—è –Ω–∞ –Ω–æ–ª—å, –µ—Å–ª–∏ —Ç–µ–∫—É—â–∏–π –ø–æ—Ä–æ–≥ —Å–ª–∏—à–∫–æ–º –≤—ã—Å–æ–∫ –∏ –Ω–µ –Ω–∞—Ö–æ–¥–∏—Ç –∫–ª–∞—Å—Å 1
    if 1 in current_preds:
        # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ F1-score –¥–ª—è –∫–ª–∞—Å—Å–∞ 1 (–º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–æ)
        current_f1 = f1_score(y_test, current_preds, average='binary', pos_label=1)

        if current_f1 > best_f1:
            best_f1 = current_f1
            best_thresh = thresh

print(f"\n–ù–∞–∏–ª—É—á—à–∏–π F1-score ({best_f1:.4f}) –¥–æ—Å—Ç–∏–≥–Ω—É—Ç –ø—Ä–∏ –ø–æ—Ä–æ–≥–µ: {best_thresh:.3f}")

# preds_new = (probs > best_thresh).astype(int)
#
# # =========================================================================================================================== #
# #                   –¢–µ—Å—Ç —Å–≤–æ–µ–≥–æ –ø–æ—Ä–æ–≥–∞
# # =========================================================================================================================== #
# optimal_threshold = 0.012
# probs = model_w.predict_proba(X_test_final)[:, 1]
# preds_final = (probs >= optimal_threshold).astype(int)
# print("\n=== –†–ï–ó–£–õ–¨–¢–ê–¢–´ –° –°–û–ë–°–¢–í–ï–ù–ù–´–ú –ü–û–†–û–ì–û–ú ===")
# print("AUC:", roc_auc_score(y_test, probs))
# print(classification_report(y_test, preds_final))
# # =========================================================================================================================== #
# # =========================================================================================================================== #
#
# print("\n=== –†–ï–ó–£–õ–¨–¢–ê–¢–´ –° –û–ü–¢–ò–ú–ê–õ–¨–ù–´–ú –ü–û–†–û–ì–û–ú ===")
# print(classification_report(y_test, preds_new))
#
# print("\n=== –†–ï–ó–£–õ–¨–¢–ê–¢–´ –° –°–¢–ê–ù–î–ê–†–¢–ù–´–ú –ü–û–†–û–ì–û–ú ===")
# print("AUC:", roc_auc_score(y_test, probs))
# print(classification_report(y_test, preds))

# =========================================================================================================================== #
#                   –¢–µ—Å—Ç —Å–≤–æ–µ–≥–æ –ø–æ—Ä–æ–≥–∞
# =========================================================================================================================== #
optimal_threshold = 0.025
# optimal_threshold = 0.012
probs_custom = model_w.predict_proba(X_test_final)[:, 1]
preds_custom = (probs_custom >= optimal_threshold).astype(int)
print("\n=== –†–ï–ó–£–õ–¨–¢–ê–¢–´ –° –°–û–ë–°–¢–í–ï–ù–ù–´–ú –ü–û–†–û–ì–û–ú (0.025) ===")
print("AUC:", roc_auc_score(y_test, probs_custom))
print(classification_report(y_test, preds_custom))

# –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫ –¥–ª—è —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –ø–æ—Ä–æ–≥–∞
cm_custom = confusion_matrix(y_test, preds_custom)
print("–ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫ (–ø–æ—Ä–æ–≥ 0.025):")
print(cm_custom)
print(f"–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–∞: {cm_custom[1, 1]}/{cm_custom[1].sum()}")
# =========================================================================================================================== #
# =========================================================================================================================== #
print("\n=== –†–ï–ó–£–õ–¨–¢–ê–¢–´ –° –û–ü–¢–ò–ú–ê–õ–¨–ù–´–ú –ü–û–†–û–ì–û–ú ===")
# –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º, —á—Ç–æ best_thresh —É–∂–µ –≤—ã—á–∏—Å–ª–µ–Ω –≥–¥–µ-—Ç–æ —Ä–∞–Ω–µ–µ
probs_optimal = model_w.predict_proba(X_test_final)[:, 1]
preds_optimal = (probs_optimal > best_thresh).astype(int)
print("AUC:", roc_auc_score(y_test, probs_optimal))
print(f"–û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥: {best_thresh:.4f}")
print(classification_report(y_test, preds_optimal))

# –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫ –¥–ª—è –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ –ø–æ—Ä–æ–≥–∞
cm_optimal = confusion_matrix(y_test, preds_optimal)
print("–ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫ (–æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥):")
print(cm_optimal)
print(f"–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–∞: {cm_optimal[1, 1]}/{cm_optimal[1].sum()}")
# =========================================================================================================================== #
# =========================================================================================================================== #
print("\n=== –†–ï–ó–£–õ–¨–¢–ê–¢–´ –° –°–¢–ê–ù–î–ê–†–¢–ù–´–ú –ü–û–†–û–ì–û–ú (0.5) ===")
probs_standard = model_w.predict_proba(X_test_final)[:, 1]
preds_standard = (probs_standard > 0.5).astype(int)
print("AUC:", roc_auc_score(y_test, probs_standard))
print(classification_report(y_test, preds_standard))

# –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫ –¥–ª—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–≥–æ –ø–æ—Ä–æ–≥–∞
cm_standard = confusion_matrix(y_test, preds_standard)
print("–ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫ (—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –ø–æ—Ä–æ–≥ 0.5):")
print(cm_standard)
print(f"–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–∞: {cm_standard[1, 1]}/{cm_standard[1].sum()}")



all_features = X_train_final.columns.tolist()
feature_importances_array = model_w.get_feature_importance()
importance_df = pd.DataFrame({
    "feature": all_features,
    "importance": feature_importances_array
}).sort_values(by="importance", ascending=False)
print("\nüîù –¢–û–ü-20 –í–ê–ñ–ù–´–• –ü–†–ò–ó–ù–ê–ö–û–í:")
print(importance_df.head(20).to_string(index=False))